{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1661160264964,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "Zga7NYxZD3NW",
    "outputId": "b11d7678-5392-4287-982e-ecc00e1cbdcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  NN classifier (keras.models.Sequential)\\n  A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  NN classifier (keras.models.Sequential)\n",
    "  A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH7_n3GKE508"
   },
   "source": [
    "## Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6546,
     "status": "ok",
     "timestamp": 1661160274279,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "6DOSknNERAL0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Pre-processing\n",
    "import scipy.sparse as sp\n",
    "from scipy import sparse\n",
    "\n",
    "## Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## NN Classifier\n",
    "## Sequential model: Plain stack of layers where each layer has exactly one input tensor and one output tensor\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras import callbacks ## Early Stopping\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from sklearn.preprocessing import normalize ## Scale input vectors individually to unit norm (vector length)\n",
    "\n",
    "# import umap ## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1661160274280,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "2KU1Aif6MFez"
   },
   "outputs": [],
   "source": [
    "protein_list = pd.read_csv('protein_list.csv')\n",
    "# protein_list.columns = ['idx', 'Protein1_ID']\n",
    "## protein_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Protein1_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P03428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P03431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P03433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P03452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P03466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15680</th>\n",
       "      <td>15680</td>\n",
       "      <td>Q6NUS8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15681</th>\n",
       "      <td>15681</td>\n",
       "      <td>P12018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>15682</td>\n",
       "      <td>Q96IU2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15683</th>\n",
       "      <td>15683</td>\n",
       "      <td>Q6PEW1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15684</th>\n",
       "      <td>15684</td>\n",
       "      <td>P0CG32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15685 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 Protein1_ID\n",
       "0               0      P03428\n",
       "1               1      P03431\n",
       "2               2      P03433\n",
       "3               3      P03452\n",
       "4               4      P03466\n",
       "...           ...         ...\n",
       "15680       15680      Q6NUS8\n",
       "15681       15681      P12018\n",
       "15682       15682      Q96IU2\n",
       "15683       15683      Q6PEW1\n",
       "15684       15684      P0CG32\n",
       "\n",
       "[15685 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v18Zes8DW3z_"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KilEZ5Hc3oeC"
   },
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1661160274281,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "hc2laz333p-4"
   },
   "outputs": [],
   "source": [
    "def normalize_row(mx): ## Sum of each row = 1\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1)) \n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgKoqDq3QrGU"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1661160274281,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "CTofFEKxQp8z"
   },
   "outputs": [],
   "source": [
    "## Add F1, ROC-AUC and PR-AUC\n",
    "\n",
    "def calculate_metrics(y_label, y_pred, y_pred_f):\n",
    "    \n",
    "    print(y_pred)\n",
    "#     print(y_pred_f)\n",
    "\n",
    "    # For binary classification\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(len(y_label)):\n",
    "        if y_label[i] == y_pred[i]:\n",
    "            if y_label[i] == 1:\n",
    "                TP = TP + 1\n",
    "            else:\n",
    "                TN = TN + 1\n",
    "        else:\n",
    "            if y_pred[i] == 1:\n",
    "                FP = FP + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "    \n",
    "    print(\"[TP TN FP FN]\")\n",
    "    print(TP, TN, FP, FN)\n",
    "\n",
    "    accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "    sensitivity = TP / float(TP + FN)\n",
    "    specificity = TN / float(TN + FP)\n",
    "\n",
    "    ## ZeroDivisionError: float division by zero\n",
    "    try:\n",
    "        precision = TP / float(TP + FP)\n",
    "        F1 = (2 * precision * sensitivity) / (precision + sensitivity)\n",
    "    \n",
    "    except ZeroDivisionError as e:\n",
    "        print(e)\n",
    "        precision = 0.0\n",
    "        F1 = 0.0\n",
    "\n",
    "    ROC_AUC = roc_auc_score(y_label, y_pred_f)\n",
    "    PR_AUC = average_precision_score(y_label, y_pred_f)\n",
    "\n",
    "    print(\"[accuracy, sensitivity, specificity, precision, F1, ROC_AUC, PR_AUC]\")\n",
    "    return [accuracy, sensitivity, specificity, precision, F1, ROC_AUC, PR_AUC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3WWGUnlW64e"
   },
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1661160274282,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "mTpF8ijxEy1L"
   },
   "outputs": [],
   "source": [
    "def create_fold():\n",
    "\n",
    "    ## Hold-out test set\n",
    "#     test_df = pd.read_csv('edges/Sept_2022_new/balanced/idx/b_test_idx.csv') ## Network Reconstruction\n",
    "    \n",
    "    '''\n",
    "        Experimentally Verified Datasets\n",
    "    '''\n",
    "#     test_df = pd.read_csv('edges/Experimentally_Verified_Test/testset_1.csv')\n",
    "#     test_df = pd.read_csv('edges/Experimentally_Verified_Test/expt_test_new_dec2022.csv') ## Changed pos label\n",
    "#     test_df = pd.read_csv('edges/Experimentally_Verified_Test/expt_test_final_dec2022.csv') ## Changed all pos samples\n",
    "    test_df = pd.read_csv('edges/Experimentally_Verified_Test/testset_3.csv')\n",
    "    \n",
    "    pos_test = test_df[test_df['label'] == 1]  ## Standard\n",
    "    neg_test = test_df[test_df['label'] == 0]\n",
    "    \n",
    "    ## Training and Validation Set\n",
    "    pos_org = pd.read_csv('edges/Sept_2022_new/balanced/idx/b_pos_idx.csv') ## Standard\n",
    "    neg_org = pd.read_csv('edges/Sept_2022_new/balanced/idx/b_neg_idx.csv')\n",
    "    \n",
    "    '''\n",
    "        Shuffle Data\n",
    "    '''\n",
    "    pos = shuffle(pos_org)\n",
    "    neg = shuffle(neg_org)\n",
    "    \n",
    "    ## Train : Val = 9 : 1\n",
    "    pos_val = pos.sample(frac = 0.1, replace = False) ## 10% of positive dataset\n",
    "    pos_train = pos[~pos.index.isin(pos_val.index)]\n",
    "    \n",
    "    neg_val = neg.sample(frac = 0.1, replace = False) ## 10% of negative dataset\n",
    "    neg_train = neg[~neg.index.isin(neg_val.index)]\n",
    "    \n",
    "    print('--Sampled new data--')\n",
    "    \n",
    "    return pos_train, neg_train, pos_val, neg_val, pos_test, neg_test ## train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1661160274282,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "TgiMT9kxL3n0"
   },
   "outputs": [],
   "source": [
    "## Read embeddings of all proteins\n",
    "\n",
    "def read_embedding_matrix(emb_type, emb_mtd):\n",
    "    \n",
    "    protein_list_len = len(protein_list)\n",
    "    \n",
    "    if emb_type == 'graph':\n",
    "            \n",
    "        '''\n",
    "            Methods:\n",
    "                deepwalk\n",
    "                node2vec_nw8_wl32\n",
    "                struc2vec\n",
    "                SDNE\n",
    "                LINE --LINE/Order1/2/3\n",
    "                GraRep\n",
    "                VAE_epochs200/VAE_epochs5\n",
    "                ripple2vec\n",
    "                node2vec_plus_nw8_wl32 ## SparseOTF\n",
    "        '''\n",
    "        \n",
    "#         set_emb_name = 'node2vec_plus_nw8_wl32' \n",
    "#         edit_data_path = 'Embeddings/Graph/' + set_emb_name + '/'\n",
    "        \n",
    "        edit_data_path = 'Embeddings/Graph/Best/Nov_2022/' \n",
    "\n",
    "        '''\n",
    "            Load Embeddings\n",
    "        '''\n",
    "        ## Deepwalk, node2vec, struc2vec\n",
    "#         emb = pd.read_csv(edit_data_path + emb_mtd + '.csv', skiprows=1, header = None).sort_values(by = [0]).set_index([0])\n",
    "        \n",
    "        ## SDNE, GraRep, VAE, ripple2vec, (LINE)\n",
    "#         emb = pd.read_csv(edit_data_path + emb_mtd + '.txt', sep=' ', skiprows=1, header = None).sort_values(by = [0]).set_index([0])\n",
    "        \n",
    "        ## node2vec+\n",
    "        emb = pd.read_csv(edit_data_path + emb_mtd + '.emb', sep=' ', skiprows=1, header = None).sort_values(by = [0]).set_index([0]) \n",
    "        \n",
    "        ## Convert csv to array\n",
    "        for i in np.setdiff1d(np.arange(protein_list_len), emb.index.values): ## setdiff1d: 1D array of values in ar1 that are not in ar2\n",
    "            emb.loc[i] = (np.sum(emb.values, axis = 0)/emb.values.shape[0]) ## manually insert emb for protein indexes with no node2vec embedding\n",
    "        features_def = emb.sort_index().values\n",
    "        \n",
    "    ### Read sparse matrix directly\n",
    "    else:\n",
    "        \n",
    "        if emb_type == 'combination':\n",
    "            \n",
    "            ### Combination of graph embeddings\n",
    "            edit_data_path = 'Embeddings/Graph/Best/Concat/'\n",
    "            \n",
    "            ### Protein + Graph embeddings\n",
    "            # edit_data_path = data_path + 'concat_embeddings/'\n",
    "            \n",
    "        elif emb_type == 'protein':\n",
    "            edit_data_path = data_path + 'protein_embeddings/'\n",
    "\n",
    "        elif emb_type == 'feat_selection':\n",
    "            edit_data_path = data_path + 'protein_embeddings/feature_selection/'\n",
    "    \n",
    "        read_emb = sparse.load_npz(edit_data_path + emb_mtd + '.npz')\n",
    "        features_def = read_emb.toarray()\n",
    "    \n",
    "    features = normalize_row(features_def) ## Row-normalize features\n",
    "#     features = normalize(features_def) ## from sklearn.preprocessing\n",
    "    \n",
    "    print(\"---Read Embeddings---\")\n",
    "    print(features.shape)\n",
    "    print(features_def)\n",
    "    print(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN7REN3__vHv"
   },
   "source": [
    "### Retrieve embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1661160274283,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "4ujYwOZw4qoB"
   },
   "outputs": [],
   "source": [
    "def hadamard_emb(emb, posEdges, negEdges):\n",
    "    \n",
    "    posNum = posEdges.shape[0]\n",
    "    negNum = negEdges.shape[0]\n",
    "    \n",
    "    X = np.empty((posNum+negNum, emb.shape[1])) ## All embeddings\n",
    "    k = 0\n",
    "    \n",
    "    for i in posEdges.index:\n",
    "        u = emb[posEdges['Protein1_ID'][i]]\n",
    "        v = emb[posEdges['Protein2_ID'][i]]\n",
    "\n",
    "        hadamard = np.multiply(u, v)\n",
    "\n",
    "        X[k] = hadamard\n",
    "        k = k + 1\n",
    "            \n",
    "    for i in negEdges.index:\n",
    "        u = emb[negEdges['Protein1_ID'][i]]\n",
    "        v = emb[negEdges['Protein2_ID'][i]]\n",
    "\n",
    "        hadamard = np.multiply(u, v)\n",
    "        \n",
    "        X[k] = hadamard\n",
    "        k = k + 1\n",
    "        \n",
    "    Y_pos = np.full((posNum,2),[0,1])\n",
    "    Y_neg = np.full((negNum,2),[1,0])\n",
    "    Y = np.vstack((Y_pos,Y_neg))\n",
    "\n",
    "      # print(\"---Generate data---\")\n",
    "      # print(X)\n",
    "      # print(X.shape) ## (2D array)\n",
    "      # print(Y.shape)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BskvyPPShNP"
   },
   "source": [
    "## trainNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1661160274283,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "3QkL2KBOSjsN"
   },
   "outputs": [],
   "source": [
    "def train_nn(X_train, Y_train, X_val, Y_val, X_test, Y_test): \n",
    "\n",
    "    print(\"---TrainNN---\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=X_train.shape[1])) ## Input layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam', ## Adam optimization\n",
    "                    metrics=['accuracy'])\n",
    "    \n",
    "    print(K.eval(model.optimizer.lr))\n",
    "    \n",
    "#     model.fit(X_train, Y_train, epochs=200, batch_size=128, verbose=1)\n",
    "\n",
    "    ## Early stopping on validation dataset (10% of overall dataset)\n",
    "    earlystopping = callbacks.EarlyStopping(monitor='val_loss', mode=\"min\", patience=20, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=200, batch_size=128, validation_data=(X_val, Y_val), callbacks=[earlystopping])\n",
    "\n",
    "    ### Using Hold-out Test Set (X_test and Y_test)\n",
    "    y_prob = model.predict(X_test)\n",
    "\n",
    "    ## Binary prediction (y_pred)\n",
    "    y_classes = y_prob.argmax(axis=1) \n",
    "\n",
    "    ## Float prediction\n",
    "    y_pred_f = y_prob[:,1] ## Probability of belonging to class label '1' \n",
    "\n",
    "    ## True class labels\n",
    "    y_true = Y_test[:,1]\n",
    "\n",
    "    acc = calculate_metrics(y_true, y_classes, y_pred_f) ## calculate_metrics(y_label, y_pred, y_pred_f)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOsvOYfZQyi9"
   },
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1661160274284,
     "user": {
      "displayName": "ann ng",
      "userId": "16723765352528695909"
     },
     "user_tz": -480
    },
    "id": "yl6EMf9DQEXO"
   },
   "outputs": [],
   "source": [
    "def train(input_type, input_mtd):\n",
    "\n",
    "    ## Call create_fold()\n",
    "    train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = create_fold()\n",
    "\n",
    "    print(train_edges.shape,train_edges_false.shape)\n",
    "    print(val_edges.shape,val_edges_false.shape)\n",
    "    print(test_edges.shape,test_edges_false.shape)\n",
    "\n",
    "    ## Retrieve embeddings of all proteins \n",
    "    emb = read_embedding_matrix(input_type, input_mtd) ## embedding method\n",
    "    \n",
    "    ## UMAP reduce dimension of embedding to 2\n",
    "#     emb = umap.UMAP().fit_transform(emb_org)\n",
    "    \n",
    "    ## Retrieve embeddings of respective nodes \n",
    "    X_train,Y_train = hadamard_emb(emb, train_edges, train_edges_false)\n",
    "    X_val, Y_val = hadamard_emb(emb, val_edges, val_edges_false)\n",
    "    X_test,Y_test = hadamard_emb(emb, test_edges, test_edges_false)\n",
    "\n",
    "    ## Final softmax classifier\n",
    "    acc = train_nn(X_train,Y_train,X_val,Y_val,X_test,Y_test)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ltzfy5vacFGp"
   },
   "source": [
    "## Run program here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prog(input_graph_emb):\n",
    "    \n",
    "    eval_metrics = []\n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        \n",
    "        print('Iteration(train): ', (i+1))\n",
    "        \n",
    "        acc = train(input_type = 'graph', input_mtd=input_graph_emb) ## input_type = 'graph', 'combination'\n",
    "        print(acc)\n",
    "        \n",
    "        eval_metrics.append(acc)\n",
    "        \n",
    "    print(\"===================== \" + input_graph_emb + \" =====================\")\n",
    "    print(eval_metrics)\n",
    "    \n",
    "    mean = np.array(eval_metrics).mean(axis=0) # Take the mean of each column\n",
    "    mean = np.round(mean, 4)\n",
    "    print('Mean: ' + str(mean)[1:-1])\n",
    "          \n",
    "    max = np.array(eval_metrics).max(axis=0)\n",
    "    max = np.round(max, 4)\n",
    "    print('Max: ' + str(max)[1:-1])\n",
    "          \n",
    "    min = np.array(eval_metrics).min(axis=0)\n",
    "    min = np.round(min, 4)\n",
    "    print('Min: ' + str(min)[1:-1])\n",
    "    print(\"=======================================================\")\n",
    "        \n",
    "    with open('Eval_Results/Testset2_Experimentally_Verified.txt', \"a\") as f:\n",
    "        f.write(input_graph_emb + '(mean):' + str(mean) + '\\n')\n",
    "#         f.write(input_graph_emb + '(max):' + str(max) + '\\n')\n",
    "#         f.write(input_graph_emb + '(min):' + str(min) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtd_arr = ['deepwalk_nw16_wl32', 'node2vec_nw8_wl32_p0.25_q0.5', 'struc2vec_nw128_wl16']\n",
    "# mtd_arr = ['ripple2vec_nw8_wl8', 'vae_h256_128', 'grarep_k2']\n",
    "# mtd_arr = ['LINE_order3_epochs10', 'sdne_a0_b10', 'ripple2vec_nw8_wl8']\n",
    "\n",
    "# for i in range(len(mtd_arr)):\n",
    "#     run_prog(mtd_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration(train):  1\n",
      "--Sampled new data--\n",
      "(3613, 3) (3613, 3)\n",
      "(401, 3) (401, 3)\n",
      "(446, 3) (446, 3)\n",
      "---Read Embeddings---\n",
      "(15685, 128)\n",
      "[[ 0.05438794  0.15712513  0.02526474 ...  0.06337012 -0.06831192\n",
      "   0.05740243]\n",
      " [ 0.0920557   0.12854572  0.07927883 ... -0.04355874 -0.02950621\n",
      "   0.01127648]\n",
      " [ 0.10265665  0.04119997  0.01358521 ... -0.07648639  0.01284278\n",
      "   0.09610651]\n",
      " ...\n",
      " [-0.06547894  0.03663263  0.12268668 ... -0.04719101 -0.08261108\n",
      "  -0.08350137]\n",
      " [-0.00914692 -0.00912238  0.11259656 ... -0.02135581 -0.1477403\n",
      "  -0.11278752]\n",
      " [ 0.02491135 -0.00382214  0.14209396 ...  0.0124865  -0.13294958\n",
      "  -0.08357669]]\n",
      "[[ 0.06255813  0.18072855  0.02906002 ...  0.07288961 -0.07857377\n",
      "   0.06602545]\n",
      " [ 0.18997227  0.26527551  0.16360507 ... -0.08989072 -0.06089097\n",
      "   0.0232709 ]\n",
      " [-0.20810853 -0.08352177 -0.02754034 ...  0.15505543 -0.02603526\n",
      "  -0.19482991]\n",
      " ...\n",
      " [ 0.07148592 -0.03999328 -0.13394184 ...  0.05152027  0.09018974\n",
      "   0.09116171]\n",
      " [ 0.01469648  0.01465706 -0.18091049 ...  0.03431268  0.23737643\n",
      "   0.1812173 ]\n",
      " [-0.10046136  0.01541376 -0.57303013 ... -0.05035501  0.53615309\n",
      "   0.33704433]]\n",
      "---TrainNN---\n",
      "0.001\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 2s 8ms/step - loss: 0.8484 - accuracy: 0.5530 - val_loss: 0.6762 - val_accuracy: 0.6633\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7312 - accuracy: 0.5995 - val_loss: 0.6410 - val_accuracy: 0.6122\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6351 - val_loss: 0.5969 - val_accuracy: 0.7145\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.6618 - val_loss: 0.5636 - val_accuracy: 0.7444\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7083 - val_loss: 0.5413 - val_accuracy: 0.6883\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7243 - val_loss: 0.4846 - val_accuracy: 0.7968\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7598 - val_loss: 0.4475 - val_accuracy: 0.8142\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7776 - val_loss: 0.4222 - val_accuracy: 0.8404\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8137 - val_loss: 0.3750 - val_accuracy: 0.8903\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8330 - val_loss: 0.3492 - val_accuracy: 0.9040\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8438 - val_loss: 0.2999 - val_accuracy: 0.9077\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.8472 - val_loss: 0.2908 - val_accuracy: 0.9090\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8724 - val_loss: 0.2779 - val_accuracy: 0.8965\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8680 - val_loss: 0.2555 - val_accuracy: 0.9214\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8829 - val_loss: 0.2434 - val_accuracy: 0.9177\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8894 - val_loss: 0.2223 - val_accuracy: 0.9190\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8972 - val_loss: 0.2155 - val_accuracy: 0.9177\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8976 - val_loss: 0.2220 - val_accuracy: 0.9227\n",
      "Epoch 19/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8991 - val_loss: 0.2074 - val_accuracy: 0.9264\n",
      "Epoch 20/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.9026 - val_loss: 0.1966 - val_accuracy: 0.9327\n",
      "Epoch 21/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.9011 - val_loss: 0.1980 - val_accuracy: 0.9227\n",
      "Epoch 22/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.9008 - val_loss: 0.1912 - val_accuracy: 0.9264\n",
      "Epoch 23/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.9114 - val_loss: 0.1957 - val_accuracy: 0.9327\n",
      "Epoch 24/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.9074 - val_loss: 0.1820 - val_accuracy: 0.9327\n",
      "Epoch 25/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9148 - val_loss: 0.1870 - val_accuracy: 0.9277\n",
      "Epoch 26/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.9117 - val_loss: 0.1789 - val_accuracy: 0.9339\n",
      "Epoch 27/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.9136 - val_loss: 0.1809 - val_accuracy: 0.9339\n",
      "Epoch 28/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.9142 - val_loss: 0.1926 - val_accuracy: 0.9239\n",
      "Epoch 29/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9154 - val_loss: 0.1774 - val_accuracy: 0.9352\n",
      "Epoch 30/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9224 - val_loss: 0.1690 - val_accuracy: 0.9339\n",
      "Epoch 31/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9262 - val_loss: 0.1656 - val_accuracy: 0.9426\n",
      "Epoch 32/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9271 - val_loss: 0.1659 - val_accuracy: 0.9439\n",
      "Epoch 33/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9267 - val_loss: 0.1731 - val_accuracy: 0.9401\n",
      "Epoch 34/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9276 - val_loss: 0.1619 - val_accuracy: 0.9426\n",
      "Epoch 35/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9315 - val_loss: 0.1717 - val_accuracy: 0.9377\n",
      "Epoch 36/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9301 - val_loss: 0.1640 - val_accuracy: 0.9439\n",
      "Epoch 37/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9315 - val_loss: 0.1691 - val_accuracy: 0.9377\n",
      "Epoch 38/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9352 - val_loss: 0.1628 - val_accuracy: 0.9414\n",
      "Epoch 39/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9333 - val_loss: 0.1641 - val_accuracy: 0.9426\n",
      "Epoch 40/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9343 - val_loss: 0.1649 - val_accuracy: 0.9401\n",
      "Epoch 41/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9318 - val_loss: 0.2809 - val_accuracy: 0.8591\n",
      "Epoch 42/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2887 - accuracy: 0.8796 - val_loss: 0.1843 - val_accuracy: 0.9277\n",
      "Epoch 43/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9174 - val_loss: 0.1638 - val_accuracy: 0.9401\n",
      "Epoch 44/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.9232 - val_loss: 0.2009 - val_accuracy: 0.9102\n",
      "Epoch 45/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9175 - val_loss: 0.1563 - val_accuracy: 0.9414\n",
      "Epoch 46/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9312 - val_loss: 0.1628 - val_accuracy: 0.9401\n",
      "Epoch 47/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9309 - val_loss: 0.1551 - val_accuracy: 0.9451\n",
      "Epoch 48/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9315 - val_loss: 0.1550 - val_accuracy: 0.9451\n",
      "Epoch 49/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9370 - val_loss: 0.1556 - val_accuracy: 0.9451\n",
      "Epoch 50/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9399 - val_loss: 0.1562 - val_accuracy: 0.9451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9386 - val_loss: 0.1552 - val_accuracy: 0.9426\n",
      "Epoch 52/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9391 - val_loss: 0.1563 - val_accuracy: 0.9451\n",
      "Epoch 53/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9380 - val_loss: 0.1485 - val_accuracy: 0.9439\n",
      "Epoch 54/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9356 - val_loss: 0.1565 - val_accuracy: 0.9439\n",
      "Epoch 55/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9404 - val_loss: 0.1545 - val_accuracy: 0.9476\n",
      "Epoch 56/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9394 - val_loss: 0.1541 - val_accuracy: 0.9451\n",
      "Epoch 57/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9455 - val_loss: 0.1504 - val_accuracy: 0.9451\n",
      "Epoch 58/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9431 - val_loss: 0.1535 - val_accuracy: 0.9489\n",
      "Epoch 59/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9427 - val_loss: 0.1544 - val_accuracy: 0.9426\n",
      "Epoch 60/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9433 - val_loss: 0.1561 - val_accuracy: 0.9464\n",
      "Epoch 61/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9422 - val_loss: 0.1641 - val_accuracy: 0.9476\n",
      "Epoch 62/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9452 - val_loss: 0.1623 - val_accuracy: 0.9451\n",
      "Epoch 63/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9431 - val_loss: 0.1630 - val_accuracy: 0.9451\n",
      "Epoch 64/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9426 - val_loss: 0.1598 - val_accuracy: 0.9489\n",
      "Epoch 65/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9426 - val_loss: 0.1471 - val_accuracy: 0.9489\n",
      "Epoch 66/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9451 - val_loss: 0.1475 - val_accuracy: 0.9464\n",
      "Epoch 67/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9477 - val_loss: 0.1518 - val_accuracy: 0.9489\n",
      "Epoch 68/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1546 - accuracy: 0.9456 - val_loss: 0.1587 - val_accuracy: 0.9489\n",
      "Epoch 69/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9440 - val_loss: 0.1546 - val_accuracy: 0.9476\n",
      "Epoch 70/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9478 - val_loss: 0.1573 - val_accuracy: 0.9489\n",
      "Epoch 71/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9452 - val_loss: 0.1603 - val_accuracy: 0.9476\n",
      "Epoch 72/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9500 - val_loss: 0.1604 - val_accuracy: 0.9476\n",
      "Epoch 73/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9428 - val_loss: 0.1633 - val_accuracy: 0.9464\n",
      "Epoch 74/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9477 - val_loss: 0.1613 - val_accuracy: 0.9476\n",
      "Epoch 75/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9445 - val_loss: 0.1463 - val_accuracy: 0.9426\n",
      "Epoch 76/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9471 - val_loss: 0.1446 - val_accuracy: 0.9514\n",
      "Epoch 77/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9469 - val_loss: 0.1548 - val_accuracy: 0.9489\n",
      "Epoch 78/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9477 - val_loss: 0.1571 - val_accuracy: 0.9464\n",
      "Epoch 79/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9482 - val_loss: 0.1670 - val_accuracy: 0.9501\n",
      "Epoch 80/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9520 - val_loss: 0.1653 - val_accuracy: 0.9489\n",
      "Epoch 81/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9506 - val_loss: 0.1625 - val_accuracy: 0.9489\n",
      "Epoch 82/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9481 - val_loss: 0.1719 - val_accuracy: 0.9489\n",
      "Epoch 83/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9516 - val_loss: 0.1691 - val_accuracy: 0.9476\n",
      "Epoch 84/200\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9491 - val_loss: 0.1494 - val_accuracy: 0.9476\n",
      "Epoch 85/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9498 - val_loss: 0.1626 - val_accuracy: 0.9489\n",
      "Epoch 86/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9507 - val_loss: 0.1697 - val_accuracy: 0.9489\n",
      "Epoch 87/200\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9493 - val_loss: 0.1501 - val_accuracy: 0.9489\n",
      "Epoch 88/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9485 - val_loss: 0.1540 - val_accuracy: 0.9489\n",
      "Epoch 89/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9489 - val_loss: 0.1611 - val_accuracy: 0.9489\n",
      "Epoch 90/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9499 - val_loss: 0.1584 - val_accuracy: 0.9476\n",
      "Epoch 91/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1498 - accuracy: 0.9485 - val_loss: 0.1649 - val_accuracy: 0.9489\n",
      "Epoch 92/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9383 - val_loss: 0.1564 - val_accuracy: 0.9352\n",
      "Epoch 93/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9237 - val_loss: 0.1783 - val_accuracy: 0.9177\n",
      "Epoch 94/200\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1919 - accuracy: 0.9312 - val_loss: 0.1424 - val_accuracy: 0.9514\n",
      "Epoch 95/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9431 - val_loss: 0.1544 - val_accuracy: 0.9514\n",
      "Epoch 96/200\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9487 - val_loss: 0.1588 - val_accuracy: 0.9501\n",
      "Epoch 97/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9419 - val_loss: 0.1507 - val_accuracy: 0.9501\n",
      "Epoch 98/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9456 - val_loss: 0.1533 - val_accuracy: 0.9514\n",
      "Epoch 99/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9459 - val_loss: 0.1575 - val_accuracy: 0.9489\n",
      "Epoch 100/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9503 - val_loss: 0.1555 - val_accuracy: 0.9464\n",
      "Epoch 101/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9543 - val_loss: 0.1597 - val_accuracy: 0.9501\n",
      "Epoch 102/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9536 - val_loss: 0.1610 - val_accuracy: 0.9539\n",
      "Epoch 103/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9514 - val_loss: 0.1568 - val_accuracy: 0.9501\n",
      "Epoch 104/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9509 - val_loss: 0.1555 - val_accuracy: 0.9489\n",
      "Epoch 105/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9505 - val_loss: 0.1540 - val_accuracy: 0.9501\n",
      "Epoch 106/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9545 - val_loss: 0.1590 - val_accuracy: 0.9489\n",
      "Epoch 107/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9534 - val_loss: 0.1633 - val_accuracy: 0.9514\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9521 - val_loss: 0.1621 - val_accuracy: 0.9501\n",
      "Epoch 109/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9553 - val_loss: 0.1641 - val_accuracy: 0.9526\n",
      "Epoch 110/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9498 - val_loss: 0.1470 - val_accuracy: 0.9489\n",
      "Epoch 111/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9524 - val_loss: 0.1504 - val_accuracy: 0.9501\n",
      "Epoch 112/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9532 - val_loss: 0.1557 - val_accuracy: 0.9526\n",
      "Epoch 113/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9523 - val_loss: 0.1485 - val_accuracy: 0.9489\n",
      "Epoch 114/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9539 - val_loss: 0.1494 - val_accuracy: 0.9514\n",
      "28/28 [==============================] - 0s 923us/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0\n",
      " 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0\n",
      " 0 1 1 0]\n",
      "[TP TN FP FN]\n",
      "428 105 341 18\n",
      "[accuracy, sensitivity, specificity, precision, F1, ROC_AUC, PR_AUC]\n",
      "[0.5975336322869955, 0.9596412556053812, 0.23542600896860988, 0.5565669700910273, 0.7045267489711935, 0.8313484083733838, 0.8335874001790882]\n",
      "Iteration(train):  2\n",
      "--Sampled new data--\n",
      "(3613, 3) (3613, 3)\n",
      "(401, 3) (401, 3)\n",
      "(446, 3) (446, 3)\n",
      "---Read Embeddings---\n",
      "(15685, 128)\n",
      "[[ 0.05438794  0.15712513  0.02526474 ...  0.06337012 -0.06831192\n",
      "   0.05740243]\n",
      " [ 0.0920557   0.12854572  0.07927883 ... -0.04355874 -0.02950621\n",
      "   0.01127648]\n",
      " [ 0.10265665  0.04119997  0.01358521 ... -0.07648639  0.01284278\n",
      "   0.09610651]\n",
      " ...\n",
      " [-0.06547894  0.03663263  0.12268668 ... -0.04719101 -0.08261108\n",
      "  -0.08350137]\n",
      " [-0.00914692 -0.00912238  0.11259656 ... -0.02135581 -0.1477403\n",
      "  -0.11278752]\n",
      " [ 0.02491135 -0.00382214  0.14209396 ...  0.0124865  -0.13294958\n",
      "  -0.08357669]]\n",
      "[[ 0.06255813  0.18072855  0.02906002 ...  0.07288961 -0.07857377\n",
      "   0.06602545]\n",
      " [ 0.18997227  0.26527551  0.16360507 ... -0.08989072 -0.06089097\n",
      "   0.0232709 ]\n",
      " [-0.20810853 -0.08352177 -0.02754034 ...  0.15505543 -0.02603526\n",
      "  -0.19482991]\n",
      " ...\n",
      " [ 0.07148592 -0.03999328 -0.13394184 ...  0.05152027  0.09018974\n",
      "   0.09116171]\n",
      " [ 0.01469648  0.01465706 -0.18091049 ...  0.03431268  0.23737643\n",
      "   0.1812173 ]\n",
      " [-0.10046136  0.01541376 -0.57303013 ... -0.05035501  0.53615309\n",
      "   0.33704433]]\n",
      "---TrainNN---\n",
      "0.001\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.7694 - accuracy: 0.5347 - val_loss: 0.6909 - val_accuracy: 0.6122\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7163 - accuracy: 0.6050 - val_loss: 0.6538 - val_accuracy: 0.6434\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.6301 - val_loss: 0.6369 - val_accuracy: 0.6621\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6717 - val_loss: 0.6060 - val_accuracy: 0.7145\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7015 - val_loss: 0.5569 - val_accuracy: 0.7930\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7462 - val_loss: 0.4923 - val_accuracy: 0.7955\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7753 - val_loss: 0.4427 - val_accuracy: 0.8753\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8165 - val_loss: 0.3945 - val_accuracy: 0.8853\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8386 - val_loss: 0.3431 - val_accuracy: 0.9052\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8577 - val_loss: 0.3286 - val_accuracy: 0.9090\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8724 - val_loss: 0.2928 - val_accuracy: 0.9065\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8705 - val_loss: 0.2825 - val_accuracy: 0.9077\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8923 - val_loss: 0.2552 - val_accuracy: 0.9140\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8922 - val_loss: 0.2405 - val_accuracy: 0.9152\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8995 - val_loss: 0.2561 - val_accuracy: 0.9152\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8969 - val_loss: 0.2696 - val_accuracy: 0.9152\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.9066 - val_loss: 0.2176 - val_accuracy: 0.9165\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.9096 - val_loss: 0.2159 - val_accuracy: 0.9202\n",
      "Epoch 19/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9116 - val_loss: 0.2196 - val_accuracy: 0.9239\n",
      "Epoch 20/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9153 - val_loss: 0.2038 - val_accuracy: 0.9239\n",
      "Epoch 21/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9199 - val_loss: 0.1979 - val_accuracy: 0.9314\n",
      "Epoch 22/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.9181 - val_loss: 0.2365 - val_accuracy: 0.9214\n",
      "Epoch 23/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.9200 - val_loss: 0.1910 - val_accuracy: 0.9227\n",
      "Epoch 24/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9172 - val_loss: 0.1871 - val_accuracy: 0.9239\n",
      "Epoch 25/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2176 - accuracy: 0.9268 - val_loss: 0.1895 - val_accuracy: 0.9252\n",
      "Epoch 26/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9265 - val_loss: 0.1878 - val_accuracy: 0.9314\n",
      "Epoch 27/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9308 - val_loss: 0.2216 - val_accuracy: 0.9289\n",
      "Epoch 28/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9206 - val_loss: 0.2022 - val_accuracy: 0.9277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9239 - val_loss: 0.1846 - val_accuracy: 0.9302\n",
      "Epoch 30/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9265 - val_loss: 0.1981 - val_accuracy: 0.9252\n",
      "Epoch 31/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9287 - val_loss: 0.1859 - val_accuracy: 0.9327\n",
      "Epoch 32/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9362 - val_loss: 0.1812 - val_accuracy: 0.9364\n",
      "Epoch 33/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9326 - val_loss: 0.1861 - val_accuracy: 0.9352\n",
      "Epoch 34/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9354 - val_loss: 0.1862 - val_accuracy: 0.9302\n",
      "Epoch 35/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2038 - accuracy: 0.9344 - val_loss: 0.1827 - val_accuracy: 0.9339\n",
      "Epoch 36/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9380 - val_loss: 0.1767 - val_accuracy: 0.9389\n",
      "Epoch 37/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9337 - val_loss: 0.1784 - val_accuracy: 0.9314\n",
      "Epoch 38/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9345 - val_loss: 0.1854 - val_accuracy: 0.9314\n",
      "Epoch 39/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9402 - val_loss: 0.1759 - val_accuracy: 0.9302\n",
      "Epoch 40/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9369 - val_loss: 0.1833 - val_accuracy: 0.9302\n",
      "Epoch 41/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9438 - val_loss: 0.1851 - val_accuracy: 0.9339\n",
      "Epoch 42/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9428 - val_loss: 0.1848 - val_accuracy: 0.9339\n",
      "Epoch 43/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9410 - val_loss: 0.1861 - val_accuracy: 0.9327\n",
      "Epoch 44/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9412 - val_loss: 0.1836 - val_accuracy: 0.9364\n",
      "Epoch 45/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9408 - val_loss: 0.1779 - val_accuracy: 0.9314\n",
      "Epoch 46/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9416 - val_loss: 0.1795 - val_accuracy: 0.9327\n",
      "Epoch 47/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9422 - val_loss: 0.1785 - val_accuracy: 0.9302\n",
      "Epoch 48/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9362 - val_loss: 0.1764 - val_accuracy: 0.9327\n",
      "Epoch 49/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9384 - val_loss: 0.1759 - val_accuracy: 0.9327\n",
      "Epoch 50/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9406 - val_loss: 0.1879 - val_accuracy: 0.9339\n",
      "Epoch 51/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9428 - val_loss: 0.1821 - val_accuracy: 0.9339\n",
      "Epoch 52/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9435 - val_loss: 0.1799 - val_accuracy: 0.9352\n",
      "Epoch 53/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9327 - val_loss: 0.1715 - val_accuracy: 0.9314\n",
      "Epoch 54/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9390 - val_loss: 0.1716 - val_accuracy: 0.9327\n",
      "Epoch 55/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9383 - val_loss: 0.1863 - val_accuracy: 0.9302\n",
      "Epoch 56/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9441 - val_loss: 0.1782 - val_accuracy: 0.9327\n",
      "Epoch 57/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9451 - val_loss: 0.1768 - val_accuracy: 0.9327\n",
      "Epoch 58/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9453 - val_loss: 0.1821 - val_accuracy: 0.9352\n",
      "Epoch 59/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9445 - val_loss: 0.1618 - val_accuracy: 0.9339\n",
      "Epoch 60/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9419 - val_loss: 0.1749 - val_accuracy: 0.9327\n",
      "Epoch 61/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9459 - val_loss: 0.1715 - val_accuracy: 0.9327\n",
      "Epoch 62/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9473 - val_loss: 0.1736 - val_accuracy: 0.9377\n",
      "Epoch 63/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9460 - val_loss: 0.1735 - val_accuracy: 0.9314\n",
      "Epoch 64/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9471 - val_loss: 0.1696 - val_accuracy: 0.9352\n",
      "Epoch 65/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9482 - val_loss: 0.1710 - val_accuracy: 0.9364\n",
      "Epoch 66/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9463 - val_loss: 0.1657 - val_accuracy: 0.9389\n",
      "Epoch 67/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9488 - val_loss: 0.1682 - val_accuracy: 0.9352\n",
      "Epoch 68/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9463 - val_loss: 0.1783 - val_accuracy: 0.9364\n",
      "Epoch 69/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9487 - val_loss: 0.1720 - val_accuracy: 0.9377\n",
      "Epoch 70/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9379 - val_loss: 0.1676 - val_accuracy: 0.9264\n",
      "Epoch 71/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9487 - val_loss: 0.1742 - val_accuracy: 0.9352\n",
      "Epoch 72/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9488 - val_loss: 0.1634 - val_accuracy: 0.9327\n",
      "Epoch 73/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9495 - val_loss: 0.1704 - val_accuracy: 0.9352\n",
      "Epoch 74/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9505 - val_loss: 0.1676 - val_accuracy: 0.9426\n",
      "Epoch 75/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9514 - val_loss: 0.1550 - val_accuracy: 0.9414\n",
      "Epoch 76/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9500 - val_loss: 0.1700 - val_accuracy: 0.9352\n",
      "Epoch 77/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9491 - val_loss: 0.1663 - val_accuracy: 0.9364\n",
      "Epoch 78/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1367 - accuracy: 0.9516 - val_loss: 0.1742 - val_accuracy: 0.9364\n",
      "Epoch 79/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9549 - val_loss: 0.1779 - val_accuracy: 0.9401\n",
      "Epoch 80/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9500 - val_loss: 0.1673 - val_accuracy: 0.9401\n",
      "Epoch 81/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9491 - val_loss: 0.1612 - val_accuracy: 0.9426\n",
      "Epoch 82/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9498 - val_loss: 0.1631 - val_accuracy: 0.9389\n",
      "Epoch 83/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9545 - val_loss: 0.1805 - val_accuracy: 0.9377\n",
      "Epoch 84/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9554 - val_loss: 0.1601 - val_accuracy: 0.9377\n",
      "Epoch 85/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9531 - val_loss: 0.1767 - val_accuracy: 0.9401\n",
      "Epoch 86/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9534 - val_loss: 0.1804 - val_accuracy: 0.9377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9534 - val_loss: 0.1898 - val_accuracy: 0.9401\n",
      "Epoch 88/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9513 - val_loss: 0.1842 - val_accuracy: 0.9352\n",
      "Epoch 89/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9509 - val_loss: 0.1769 - val_accuracy: 0.9377\n",
      "Epoch 90/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9528 - val_loss: 0.1779 - val_accuracy: 0.9401\n",
      "Epoch 91/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9546 - val_loss: 0.1594 - val_accuracy: 0.9389\n",
      "Epoch 92/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9442 - val_loss: 0.1696 - val_accuracy: 0.9414\n",
      "Epoch 93/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9556 - val_loss: 0.1637 - val_accuracy: 0.9389\n",
      "Epoch 94/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9529 - val_loss: 0.1741 - val_accuracy: 0.9414\n",
      "Epoch 95/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9521 - val_loss: 0.1659 - val_accuracy: 0.9401\n",
      "28/28 [==============================] - 0s 923us/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0\n",
      " 0 1 1 0]\n",
      "[TP TN FP FN]\n",
      "428 135 311 18\n",
      "[accuracy, sensitivity, specificity, precision, F1, ROC_AUC, PR_AUC]\n",
      "[0.6311659192825112, 0.9596412556053812, 0.30269058295964124, 0.5791610284167794, 0.7223628691983123, 0.8463798789438758, 0.8405979958288516]\n",
      "Iteration(train):  3\n",
      "--Sampled new data--\n",
      "(3613, 3) (3613, 3)\n",
      "(401, 3) (401, 3)\n",
      "(446, 3) (446, 3)\n",
      "---Read Embeddings---\n",
      "(15685, 128)\n",
      "[[ 0.05438794  0.15712513  0.02526474 ...  0.06337012 -0.06831192\n",
      "   0.05740243]\n",
      " [ 0.0920557   0.12854572  0.07927883 ... -0.04355874 -0.02950621\n",
      "   0.01127648]\n",
      " [ 0.10265665  0.04119997  0.01358521 ... -0.07648639  0.01284278\n",
      "   0.09610651]\n",
      " ...\n",
      " [-0.06547894  0.03663263  0.12268668 ... -0.04719101 -0.08261108\n",
      "  -0.08350137]\n",
      " [-0.00914692 -0.00912238  0.11259656 ... -0.02135581 -0.1477403\n",
      "  -0.11278752]\n",
      " [ 0.02491135 -0.00382214  0.14209396 ...  0.0124865  -0.13294958\n",
      "  -0.08357669]]\n",
      "[[ 0.06255813  0.18072855  0.02906002 ...  0.07288961 -0.07857377\n",
      "   0.06602545]\n",
      " [ 0.18997227  0.26527551  0.16360507 ... -0.08989072 -0.06089097\n",
      "   0.0232709 ]\n",
      " [-0.20810853 -0.08352177 -0.02754034 ...  0.15505543 -0.02603526\n",
      "  -0.19482991]\n",
      " ...\n",
      " [ 0.07148592 -0.03999328 -0.13394184 ...  0.05152027  0.09018974\n",
      "   0.09116171]\n",
      " [ 0.01469648  0.01465706 -0.18091049 ...  0.03431268  0.23737643\n",
      "   0.1812173 ]\n",
      " [-0.10046136  0.01541376 -0.57303013 ... -0.05035501  0.53615309\n",
      "   0.33704433]]\n",
      "---TrainNN---\n",
      "0.001\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.8890 - accuracy: 0.5455 - val_loss: 0.6521 - val_accuracy: 0.7357\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7567 - accuracy: 0.6252 - val_loss: 0.6250 - val_accuracy: 0.7444\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6558 - val_loss: 0.5909 - val_accuracy: 0.7519\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6861 - val_loss: 0.5569 - val_accuracy: 0.7731\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.7337 - val_loss: 0.5055 - val_accuracy: 0.7743\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7562 - val_loss: 0.4508 - val_accuracy: 0.8292\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7872 - val_loss: 0.4133 - val_accuracy: 0.8429\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8104 - val_loss: 0.3839 - val_accuracy: 0.8741\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.8299 - val_loss: 0.3352 - val_accuracy: 0.8890\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8413 - val_loss: 0.3200 - val_accuracy: 0.8953\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8461 - val_loss: 0.2954 - val_accuracy: 0.9152\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8667 - val_loss: 0.2863 - val_accuracy: 0.9190\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8627 - val_loss: 0.2711 - val_accuracy: 0.9227\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8806 - val_loss: 0.2434 - val_accuracy: 0.9227\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8795 - val_loss: 0.2496 - val_accuracy: 0.9227\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8929 - val_loss: 0.2241 - val_accuracy: 0.9227\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8901 - val_loss: 0.2086 - val_accuracy: 0.9302\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8995 - val_loss: 0.2080 - val_accuracy: 0.9302\n",
      "Epoch 19/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.9016 - val_loss: 0.2019 - val_accuracy: 0.9352\n",
      "Epoch 20/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.9019 - val_loss: 0.1790 - val_accuracy: 0.9339\n",
      "Epoch 21/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8889 - val_loss: 0.1981 - val_accuracy: 0.9389\n",
      "Epoch 22/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8951 - val_loss: 0.1892 - val_accuracy: 0.9377\n",
      "Epoch 23/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.9085 - val_loss: 0.1787 - val_accuracy: 0.9414\n",
      "Epoch 24/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.9094 - val_loss: 0.1752 - val_accuracy: 0.9414\n",
      "Epoch 25/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.9149 - val_loss: 0.1753 - val_accuracy: 0.9389\n",
      "Epoch 26/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9159 - val_loss: 0.1759 - val_accuracy: 0.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9175 - val_loss: 0.1586 - val_accuracy: 0.9377\n",
      "Epoch 28/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9188 - val_loss: 0.1805 - val_accuracy: 0.9364\n",
      "Epoch 29/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9233 - val_loss: 0.1593 - val_accuracy: 0.9414\n",
      "Epoch 30/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9211 - val_loss: 0.1568 - val_accuracy: 0.9426\n",
      "Epoch 31/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9229 - val_loss: 0.1520 - val_accuracy: 0.9464\n",
      "Epoch 32/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9237 - val_loss: 0.1557 - val_accuracy: 0.9389\n",
      "Epoch 33/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9262 - val_loss: 0.1482 - val_accuracy: 0.9414\n",
      "Epoch 34/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9258 - val_loss: 0.1482 - val_accuracy: 0.9476\n",
      "Epoch 35/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9235 - val_loss: 0.1506 - val_accuracy: 0.9439\n",
      "Epoch 36/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9268 - val_loss: 0.1401 - val_accuracy: 0.9476\n",
      "Epoch 37/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9253 - val_loss: 0.1400 - val_accuracy: 0.9439\n",
      "Epoch 38/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9296 - val_loss: 0.1504 - val_accuracy: 0.9364\n",
      "Epoch 39/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9316 - val_loss: 0.1533 - val_accuracy: 0.9426\n",
      "Epoch 40/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9322 - val_loss: 0.1350 - val_accuracy: 0.9476\n",
      "Epoch 41/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9359 - val_loss: 0.1345 - val_accuracy: 0.9426\n",
      "Epoch 42/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9311 - val_loss: 0.1342 - val_accuracy: 0.9401\n",
      "Epoch 43/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9343 - val_loss: 0.1441 - val_accuracy: 0.9439\n",
      "Epoch 44/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1828 - accuracy: 0.9359 - val_loss: 0.1288 - val_accuracy: 0.9476\n",
      "Epoch 45/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9379 - val_loss: 0.1297 - val_accuracy: 0.9489\n",
      "Epoch 46/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9365 - val_loss: 0.1358 - val_accuracy: 0.9464\n",
      "Epoch 47/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9358 - val_loss: 0.1341 - val_accuracy: 0.9451\n",
      "Epoch 48/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1845 - accuracy: 0.9380 - val_loss: 0.1255 - val_accuracy: 0.9539\n",
      "Epoch 49/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9374 - val_loss: 0.1255 - val_accuracy: 0.9526\n",
      "Epoch 50/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9392 - val_loss: 0.1259 - val_accuracy: 0.9489\n",
      "Epoch 51/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9422 - val_loss: 0.1229 - val_accuracy: 0.9539\n",
      "Epoch 52/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.9174 - val_loss: 0.1461 - val_accuracy: 0.9464\n",
      "Epoch 53/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9307 - val_loss: 0.1371 - val_accuracy: 0.9464\n",
      "Epoch 54/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 0.9340 - val_loss: 0.1391 - val_accuracy: 0.9439\n",
      "Epoch 55/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9379 - val_loss: 0.1280 - val_accuracy: 0.9526\n",
      "Epoch 56/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.9354 - val_loss: 0.1277 - val_accuracy: 0.9501\n",
      "Epoch 57/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.9244 - val_loss: 0.1544 - val_accuracy: 0.9489\n",
      "Epoch 58/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9282 - val_loss: 0.1313 - val_accuracy: 0.9501\n",
      "Epoch 59/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9366 - val_loss: 0.1255 - val_accuracy: 0.9576\n",
      "Epoch 60/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1816 - accuracy: 0.9384 - val_loss: 0.1289 - val_accuracy: 0.9514\n",
      "Epoch 61/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9426 - val_loss: 0.1237 - val_accuracy: 0.9539\n",
      "Epoch 62/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9397 - val_loss: 0.1339 - val_accuracy: 0.9451\n",
      "Epoch 63/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9419 - val_loss: 0.1182 - val_accuracy: 0.9589\n",
      "Epoch 64/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9380 - val_loss: 0.1564 - val_accuracy: 0.9239\n",
      "Epoch 65/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9363 - val_loss: 0.1205 - val_accuracy: 0.9564\n",
      "Epoch 66/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9408 - val_loss: 0.1200 - val_accuracy: 0.9539\n",
      "Epoch 67/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9438 - val_loss: 0.1186 - val_accuracy: 0.9526\n",
      "Epoch 68/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9451 - val_loss: 0.1201 - val_accuracy: 0.9514\n",
      "Epoch 69/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9453 - val_loss: 0.1196 - val_accuracy: 0.9501\n",
      "Epoch 70/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9476 - val_loss: 0.1394 - val_accuracy: 0.9364\n",
      "Epoch 71/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9376 - val_loss: 0.1174 - val_accuracy: 0.9551\n",
      "Epoch 72/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9455 - val_loss: 0.1163 - val_accuracy: 0.9501\n",
      "Epoch 73/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9426 - val_loss: 0.1123 - val_accuracy: 0.9551\n",
      "Epoch 74/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9464 - val_loss: 0.1219 - val_accuracy: 0.9514\n",
      "Epoch 75/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9438 - val_loss: 0.1153 - val_accuracy: 0.9514\n",
      "Epoch 76/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9444 - val_loss: 0.1157 - val_accuracy: 0.9464\n",
      "Epoch 77/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9419 - val_loss: 0.1190 - val_accuracy: 0.9464\n",
      "Epoch 78/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9415 - val_loss: 0.1509 - val_accuracy: 0.9377\n",
      "Epoch 79/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9326 - val_loss: 0.1161 - val_accuracy: 0.9576\n",
      "Epoch 80/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9384 - val_loss: 0.1240 - val_accuracy: 0.9514\n",
      "Epoch 81/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9394 - val_loss: 0.1295 - val_accuracy: 0.9526\n",
      "Epoch 82/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9444 - val_loss: 0.1343 - val_accuracy: 0.9426\n",
      "Epoch 83/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9434 - val_loss: 0.1130 - val_accuracy: 0.9539\n",
      "Epoch 84/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9480 - val_loss: 0.1163 - val_accuracy: 0.9526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9316 - val_loss: 0.1284 - val_accuracy: 0.9439\n",
      "Epoch 86/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9433 - val_loss: 0.1204 - val_accuracy: 0.9526\n",
      "Epoch 87/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9474 - val_loss: 0.1124 - val_accuracy: 0.9564\n",
      "Epoch 88/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9482 - val_loss: 0.1082 - val_accuracy: 0.9576\n",
      "Epoch 89/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9394 - val_loss: 0.1343 - val_accuracy: 0.9389\n",
      "Epoch 90/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9390 - val_loss: 0.1131 - val_accuracy: 0.9564\n",
      "Epoch 91/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9446 - val_loss: 0.1115 - val_accuracy: 0.9613\n",
      "Epoch 92/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9478 - val_loss: 0.1130 - val_accuracy: 0.9539\n",
      "Epoch 93/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9477 - val_loss: 0.1118 - val_accuracy: 0.9564\n",
      "Epoch 94/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9532 - val_loss: 0.1099 - val_accuracy: 0.9589\n",
      "Epoch 95/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9459 - val_loss: 0.1319 - val_accuracy: 0.9514\n",
      "Epoch 96/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9449 - val_loss: 0.1072 - val_accuracy: 0.9589\n",
      "Epoch 97/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9452 - val_loss: 0.1103 - val_accuracy: 0.9589\n",
      "Epoch 98/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9495 - val_loss: 0.1089 - val_accuracy: 0.9576\n",
      "Epoch 99/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9473 - val_loss: 0.1041 - val_accuracy: 0.9576\n",
      "Epoch 100/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9503 - val_loss: 0.1034 - val_accuracy: 0.9576\n",
      "Epoch 101/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9517 - val_loss: 0.0997 - val_accuracy: 0.9601\n",
      "Epoch 102/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9539 - val_loss: 0.1012 - val_accuracy: 0.9539\n",
      "Epoch 103/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9499 - val_loss: 0.1053 - val_accuracy: 0.9539\n",
      "Epoch 104/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9510 - val_loss: 0.1053 - val_accuracy: 0.9601\n",
      "Epoch 105/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9531 - val_loss: 0.1038 - val_accuracy: 0.9589\n",
      "Epoch 106/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9511 - val_loss: 0.1086 - val_accuracy: 0.9539\n",
      "Epoch 107/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9541 - val_loss: 0.1045 - val_accuracy: 0.9551\n",
      "Epoch 108/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9546 - val_loss: 0.0990 - val_accuracy: 0.9601\n",
      "Epoch 109/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9518 - val_loss: 0.1040 - val_accuracy: 0.9551\n",
      "Epoch 110/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9550 - val_loss: 0.1016 - val_accuracy: 0.9601\n",
      "Epoch 111/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9524 - val_loss: 0.1047 - val_accuracy: 0.9551\n",
      "Epoch 112/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9552 - val_loss: 0.1100 - val_accuracy: 0.9551\n",
      "Epoch 113/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9560 - val_loss: 0.1012 - val_accuracy: 0.9589\n",
      "Epoch 114/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9525 - val_loss: 0.1017 - val_accuracy: 0.9613\n",
      "Epoch 115/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1409 - accuracy: 0.9543 - val_loss: 0.1032 - val_accuracy: 0.9551\n",
      "Epoch 116/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9489 - val_loss: 0.1157 - val_accuracy: 0.9514\n",
      "Epoch 117/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9535 - val_loss: 0.1050 - val_accuracy: 0.9539\n",
      "Epoch 118/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9543 - val_loss: 0.1063 - val_accuracy: 0.9551\n",
      "Epoch 119/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9550 - val_loss: 0.1025 - val_accuracy: 0.9539\n",
      "Epoch 120/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9496 - val_loss: 0.1260 - val_accuracy: 0.9514\n",
      "Epoch 121/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9477 - val_loss: 0.1142 - val_accuracy: 0.9514\n",
      "Epoch 122/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9498 - val_loss: 0.1023 - val_accuracy: 0.9539\n",
      "Epoch 123/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9525 - val_loss: 0.0961 - val_accuracy: 0.9626\n",
      "Epoch 124/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9529 - val_loss: 0.1065 - val_accuracy: 0.9601\n",
      "Epoch 125/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9557 - val_loss: 0.1094 - val_accuracy: 0.9526\n",
      "Epoch 126/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9553 - val_loss: 0.1118 - val_accuracy: 0.9564\n",
      "Epoch 127/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9560 - val_loss: 0.1040 - val_accuracy: 0.9539\n",
      "Epoch 128/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9549 - val_loss: 0.1109 - val_accuracy: 0.9551\n",
      "Epoch 129/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.9529 - val_loss: 0.1167 - val_accuracy: 0.9526\n",
      "Epoch 130/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9520 - val_loss: 0.1009 - val_accuracy: 0.9551\n",
      "Epoch 131/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9547 - val_loss: 0.1075 - val_accuracy: 0.9539\n",
      "Epoch 132/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9588 - val_loss: 0.0999 - val_accuracy: 0.9564\n",
      "Epoch 133/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9549 - val_loss: 0.1008 - val_accuracy: 0.9589\n",
      "Epoch 134/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9460 - val_loss: 0.1771 - val_accuracy: 0.9302\n",
      "Epoch 135/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9178 - val_loss: 0.1340 - val_accuracy: 0.9526\n",
      "Epoch 136/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1380 - accuracy: 0.9499 - val_loss: 0.1057 - val_accuracy: 0.9589\n",
      "Epoch 137/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9503 - val_loss: 0.1068 - val_accuracy: 0.9564\n",
      "Epoch 138/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9535 - val_loss: 0.1016 - val_accuracy: 0.9589\n",
      "Epoch 139/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9556 - val_loss: 0.1046 - val_accuracy: 0.9613\n",
      "Epoch 140/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9477 - val_loss: 0.1196 - val_accuracy: 0.9489\n",
      "Epoch 141/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9516 - val_loss: 0.1069 - val_accuracy: 0.9601\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9556 - val_loss: 0.1057 - val_accuracy: 0.9564\n",
      "Epoch 143/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9560 - val_loss: 0.1065 - val_accuracy: 0.9589\n",
      "28/28 [==============================] - 0s 923us/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0\n",
      " 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0\n",
      " 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0\n",
      " 0 1 1 0]\n",
      "[TP TN FP FN]\n",
      "420 168 278 26\n",
      "[accuracy, sensitivity, specificity, precision, F1, ROC_AUC, PR_AUC]\n",
      "[0.6591928251121076, 0.9417040358744395, 0.37668161434977576, 0.6017191977077364, 0.7342657342657343, 0.833975145287458, 0.8322680153785684]\n",
      "Iteration(train):  4\n",
      "--Sampled new data--\n",
      "(3613, 3) (3613, 3)\n",
      "(401, 3) (401, 3)\n",
      "(446, 3) (446, 3)\n",
      "---Read Embeddings---\n",
      "(15685, 128)\n",
      "[[ 0.05438794  0.15712513  0.02526474 ...  0.06337012 -0.06831192\n",
      "   0.05740243]\n",
      " [ 0.0920557   0.12854572  0.07927883 ... -0.04355874 -0.02950621\n",
      "   0.01127648]\n",
      " [ 0.10265665  0.04119997  0.01358521 ... -0.07648639  0.01284278\n",
      "   0.09610651]\n",
      " ...\n",
      " [-0.06547894  0.03663263  0.12268668 ... -0.04719101 -0.08261108\n",
      "  -0.08350137]\n",
      " [-0.00914692 -0.00912238  0.11259656 ... -0.02135581 -0.1477403\n",
      "  -0.11278752]\n",
      " [ 0.02491135 -0.00382214  0.14209396 ...  0.0124865  -0.13294958\n",
      "  -0.08357669]]\n",
      "[[ 0.06255813  0.18072855  0.02906002 ...  0.07288961 -0.07857377\n",
      "   0.06602545]\n",
      " [ 0.18997227  0.26527551  0.16360507 ... -0.08989072 -0.06089097\n",
      "   0.0232709 ]\n",
      " [-0.20810853 -0.08352177 -0.02754034 ...  0.15505543 -0.02603526\n",
      "  -0.19482991]\n",
      " ...\n",
      " [ 0.07148592 -0.03999328 -0.13394184 ...  0.05152027  0.09018974\n",
      "   0.09116171]\n",
      " [ 0.01469648  0.01465706 -0.18091049 ...  0.03431268  0.23737643\n",
      "   0.1812173 ]\n",
      " [-0.10046136  0.01541376 -0.57303013 ... -0.05035501  0.53615309\n",
      "   0.33704433]]\n",
      "---TrainNN---\n",
      "0.001\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.8468 - accuracy: 0.5458 - val_loss: 0.6901 - val_accuracy: 0.6172\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7668 - accuracy: 0.5792 - val_loss: 0.6706 - val_accuracy: 0.7257\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.6216 - val_loss: 0.6489 - val_accuracy: 0.7456\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6633 - val_loss: 0.6079 - val_accuracy: 0.7494\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6942 - val_loss: 0.5652 - val_accuracy: 0.7681\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7160 - val_loss: 0.5307 - val_accuracy: 0.7868\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7488 - val_loss: 0.4717 - val_accuracy: 0.8304\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7753 - val_loss: 0.4257 - val_accuracy: 0.8479\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8096 - val_loss: 0.3839 - val_accuracy: 0.8678\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8263 - val_loss: 0.3491 - val_accuracy: 0.8753\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8393 - val_loss: 0.3147 - val_accuracy: 0.8878\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8497 - val_loss: 0.3119 - val_accuracy: 0.9002\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8624 - val_loss: 0.2993 - val_accuracy: 0.9015\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8698 - val_loss: 0.2831 - val_accuracy: 0.9090\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8832 - val_loss: 0.2552 - val_accuracy: 0.9127\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8844 - val_loss: 0.2462 - val_accuracy: 0.9140\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8930 - val_loss: 0.2278 - val_accuracy: 0.9277\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.9002 - val_loss: 0.2151 - val_accuracy: 0.9277\n",
      "Epoch 19/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.9046 - val_loss: 0.2139 - val_accuracy: 0.9314\n",
      "Epoch 20/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9052 - val_loss: 0.1997 - val_accuracy: 0.9302\n",
      "Epoch 21/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.9089 - val_loss: 0.2173 - val_accuracy: 0.9327\n",
      "Epoch 22/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.9112 - val_loss: 0.1981 - val_accuracy: 0.9327\n",
      "Epoch 23/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.9199 - val_loss: 0.1943 - val_accuracy: 0.9364\n",
      "Epoch 24/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.9167 - val_loss: 0.2094 - val_accuracy: 0.9302\n",
      "Epoch 25/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9199 - val_loss: 0.1950 - val_accuracy: 0.9289\n",
      "Epoch 26/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.9200 - val_loss: 0.1913 - val_accuracy: 0.9239\n",
      "Epoch 27/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.9218 - val_loss: 0.1922 - val_accuracy: 0.9302\n",
      "Epoch 28/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9280 - val_loss: 0.1883 - val_accuracy: 0.9289\n",
      "Epoch 29/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9249 - val_loss: 0.1842 - val_accuracy: 0.9339\n",
      "Epoch 30/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9260 - val_loss: 0.1843 - val_accuracy: 0.9352\n",
      "Epoch 31/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9282 - val_loss: 0.1777 - val_accuracy: 0.9327\n",
      "Epoch 32/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9285 - val_loss: 0.1793 - val_accuracy: 0.9364\n",
      "Epoch 33/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9286 - val_loss: 0.1748 - val_accuracy: 0.9364\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.9345 - val_loss: 0.1735 - val_accuracy: 0.9389\n",
      "Epoch 35/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9280 - val_loss: 0.1709 - val_accuracy: 0.9352\n",
      "Epoch 36/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9316 - val_loss: 0.1853 - val_accuracy: 0.9389\n",
      "Epoch 37/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9186 - val_loss: 0.1866 - val_accuracy: 0.9352\n",
      "Epoch 38/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9268 - val_loss: 0.1651 - val_accuracy: 0.9377\n",
      "Epoch 39/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9318 - val_loss: 0.1625 - val_accuracy: 0.9339\n",
      "Epoch 40/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9387 - val_loss: 0.1589 - val_accuracy: 0.9364\n",
      "Epoch 41/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9391 - val_loss: 0.1535 - val_accuracy: 0.9377\n",
      "Epoch 42/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9340 - val_loss: 0.1633 - val_accuracy: 0.9364\n",
      "Epoch 43/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9338 - val_loss: 0.1594 - val_accuracy: 0.9364\n",
      "Epoch 44/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9409 - val_loss: 0.1579 - val_accuracy: 0.9414\n",
      "Epoch 45/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9402 - val_loss: 0.1510 - val_accuracy: 0.9414\n",
      "Epoch 46/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9409 - val_loss: 0.1533 - val_accuracy: 0.9414\n",
      "Epoch 47/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9426 - val_loss: 0.1524 - val_accuracy: 0.9401\n",
      "Epoch 48/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9399 - val_loss: 0.1497 - val_accuracy: 0.9389\n",
      "Epoch 49/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9402 - val_loss: 0.1520 - val_accuracy: 0.9377\n",
      "Epoch 50/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9355 - val_loss: 0.1463 - val_accuracy: 0.9414\n",
      "Epoch 51/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9430 - val_loss: 0.1469 - val_accuracy: 0.9451\n",
      "Epoch 52/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9386 - val_loss: 0.1503 - val_accuracy: 0.9451\n",
      "Epoch 53/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9404 - val_loss: 0.1477 - val_accuracy: 0.9426\n",
      "Epoch 54/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9390 - val_loss: 0.1419 - val_accuracy: 0.9426\n",
      "Epoch 55/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9444 - val_loss: 0.1413 - val_accuracy: 0.9451\n",
      "Epoch 56/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9441 - val_loss: 0.1413 - val_accuracy: 0.9451\n",
      "Epoch 57/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9469 - val_loss: 0.1447 - val_accuracy: 0.9451\n",
      "Epoch 58/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9433 - val_loss: 0.1411 - val_accuracy: 0.9439\n",
      "Epoch 59/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9448 - val_loss: 0.1412 - val_accuracy: 0.9451\n",
      "Epoch 60/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9428 - val_loss: 0.1409 - val_accuracy: 0.9489\n",
      "Epoch 61/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9459 - val_loss: 0.1362 - val_accuracy: 0.9464\n",
      "Epoch 62/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9463 - val_loss: 0.1359 - val_accuracy: 0.9464\n",
      "Epoch 63/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9453 - val_loss: 0.1348 - val_accuracy: 0.9476\n",
      "Epoch 64/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9408 - val_loss: 0.1501 - val_accuracy: 0.9476\n",
      "Epoch 65/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9405 - val_loss: 0.1453 - val_accuracy: 0.9401\n",
      "Epoch 66/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9474 - val_loss: 0.1419 - val_accuracy: 0.9426\n",
      "Epoch 67/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9426 - val_loss: 0.1499 - val_accuracy: 0.9389\n",
      "Epoch 68/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9430 - val_loss: 0.1332 - val_accuracy: 0.9464\n",
      "Epoch 69/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9460 - val_loss: 0.1384 - val_accuracy: 0.9464\n",
      "Epoch 70/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9480 - val_loss: 0.1357 - val_accuracy: 0.9464\n",
      "Epoch 71/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9399 - val_loss: 0.1442 - val_accuracy: 0.9414\n",
      "Epoch 72/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9422 - val_loss: 0.1402 - val_accuracy: 0.9451\n",
      "Epoch 73/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9419 - val_loss: 0.1318 - val_accuracy: 0.9451\n",
      "Epoch 74/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9296 - val_loss: 0.1574 - val_accuracy: 0.9426\n",
      "Epoch 75/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9419 - val_loss: 0.1348 - val_accuracy: 0.9464\n",
      "Epoch 76/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9452 - val_loss: 0.1302 - val_accuracy: 0.9489\n",
      "Epoch 77/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9463 - val_loss: 0.1302 - val_accuracy: 0.9489\n",
      "Epoch 78/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9473 - val_loss: 0.1304 - val_accuracy: 0.9489\n",
      "Epoch 79/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9505 - val_loss: 0.1253 - val_accuracy: 0.9501\n",
      "Epoch 80/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9473 - val_loss: 0.1317 - val_accuracy: 0.9514\n",
      "Epoch 81/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9456 - val_loss: 0.1255 - val_accuracy: 0.9514\n",
      "Epoch 82/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9477 - val_loss: 0.1275 - val_accuracy: 0.9539\n",
      "Epoch 83/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9480 - val_loss: 0.1306 - val_accuracy: 0.9489\n",
      "Epoch 84/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9488 - val_loss: 0.1277 - val_accuracy: 0.9489\n",
      "Epoch 85/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9507 - val_loss: 0.1264 - val_accuracy: 0.9476\n",
      "Epoch 86/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9489 - val_loss: 0.1268 - val_accuracy: 0.9489\n",
      "Epoch 87/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9499 - val_loss: 0.1261 - val_accuracy: 0.9526\n",
      "Epoch 88/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9460 - val_loss: 0.1319 - val_accuracy: 0.9514\n",
      "Epoch 89/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9422 - val_loss: 0.1310 - val_accuracy: 0.9526\n",
      "Epoch 90/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9498 - val_loss: 0.1261 - val_accuracy: 0.9514\n",
      "Epoch 91/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9466 - val_loss: 0.1255 - val_accuracy: 0.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9441 - val_loss: 0.1295 - val_accuracy: 0.9526\n",
      "Epoch 93/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9484 - val_loss: 0.1266 - val_accuracy: 0.9526\n",
      "Epoch 94/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9489 - val_loss: 0.1349 - val_accuracy: 0.9439\n",
      "Epoch 95/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9503 - val_loss: 0.1291 - val_accuracy: 0.9526\n",
      "Epoch 96/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9503 - val_loss: 0.1245 - val_accuracy: 0.9526\n",
      "Epoch 97/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9492 - val_loss: 0.1214 - val_accuracy: 0.9551\n",
      "Epoch 98/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9510 - val_loss: 0.1257 - val_accuracy: 0.9514\n",
      "Epoch 99/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9513 - val_loss: 0.1251 - val_accuracy: 0.9514\n",
      "Epoch 100/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9491 - val_loss: 0.1311 - val_accuracy: 0.9489\n",
      "Epoch 101/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9502 - val_loss: 0.1268 - val_accuracy: 0.9501\n",
      "Epoch 102/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9493 - val_loss: 0.1214 - val_accuracy: 0.9514\n",
      "Epoch 103/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9525 - val_loss: 0.1181 - val_accuracy: 0.9526\n",
      "Epoch 104/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9528 - val_loss: 0.1185 - val_accuracy: 0.9539\n",
      "Epoch 105/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9541 - val_loss: 0.1229 - val_accuracy: 0.9514\n",
      "Epoch 106/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9529 - val_loss: 0.1178 - val_accuracy: 0.9526\n",
      "Epoch 107/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9549 - val_loss: 0.1184 - val_accuracy: 0.9526\n",
      "Epoch 108/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9560 - val_loss: 0.1199 - val_accuracy: 0.9526\n",
      "Epoch 109/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9535 - val_loss: 0.1182 - val_accuracy: 0.9539\n",
      "Epoch 110/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9538 - val_loss: 0.1193 - val_accuracy: 0.9551\n",
      "Epoch 111/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9549 - val_loss: 0.1210 - val_accuracy: 0.9526\n",
      "Epoch 112/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9543 - val_loss: 0.1206 - val_accuracy: 0.9539\n",
      "Epoch 113/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9550 - val_loss: 0.1168 - val_accuracy: 0.9526\n",
      "Epoch 114/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9538 - val_loss: 0.1202 - val_accuracy: 0.9526\n",
      "Epoch 115/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9545 - val_loss: 0.1203 - val_accuracy: 0.9526\n",
      "Epoch 116/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9572 - val_loss: 0.1183 - val_accuracy: 0.9576\n",
      "Epoch 117/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9541 - val_loss: 0.1143 - val_accuracy: 0.9526\n",
      "Epoch 118/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9572 - val_loss: 0.1175 - val_accuracy: 0.9564\n",
      "Epoch 119/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9574 - val_loss: 0.1242 - val_accuracy: 0.9564\n",
      "Epoch 120/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9577 - val_loss: 0.1223 - val_accuracy: 0.9539\n",
      "Epoch 121/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9549 - val_loss: 0.1222 - val_accuracy: 0.9526\n",
      "Epoch 122/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9561 - val_loss: 0.1209 - val_accuracy: 0.9576\n",
      "Epoch 123/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9543 - val_loss: 0.1154 - val_accuracy: 0.9564\n",
      "Epoch 124/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9574 - val_loss: 0.1131 - val_accuracy: 0.9576\n",
      "Epoch 125/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9556 - val_loss: 0.1219 - val_accuracy: 0.9526\n",
      "Epoch 126/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9560 - val_loss: 0.1169 - val_accuracy: 0.9539\n",
      "Epoch 127/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9546 - val_loss: 0.1143 - val_accuracy: 0.9539\n",
      "Epoch 128/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9549 - val_loss: 0.1215 - val_accuracy: 0.9564\n",
      "Epoch 129/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9538 - val_loss: 0.1199 - val_accuracy: 0.9551\n",
      "Epoch 130/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9542 - val_loss: 0.1165 - val_accuracy: 0.9551\n",
      "Epoch 131/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9553 - val_loss: 0.1119 - val_accuracy: 0.9601\n",
      "Epoch 132/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9559 - val_loss: 0.1156 - val_accuracy: 0.9576\n",
      "Epoch 133/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1198 - accuracy: 0.9557 - val_loss: 0.1206 - val_accuracy: 0.9564\n",
      "Epoch 134/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9536 - val_loss: 0.1185 - val_accuracy: 0.9539\n",
      "Epoch 135/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9539 - val_loss: 0.1156 - val_accuracy: 0.9564\n",
      "Epoch 136/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9583 - val_loss: 0.1142 - val_accuracy: 0.9551\n",
      "Epoch 137/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9624 - val_loss: 0.1096 - val_accuracy: 0.9576\n",
      "Epoch 138/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9583 - val_loss: 0.1171 - val_accuracy: 0.9514\n",
      "Epoch 139/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9590 - val_loss: 0.1068 - val_accuracy: 0.9551\n",
      "Epoch 140/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9554 - val_loss: 0.1093 - val_accuracy: 0.9539\n",
      "Epoch 141/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9579 - val_loss: 0.1101 - val_accuracy: 0.9539\n",
      "Epoch 142/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9601 - val_loss: 0.1254 - val_accuracy: 0.9489\n",
      "Epoch 143/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1688 - accuracy: 0.9453 - val_loss: 0.1858 - val_accuracy: 0.9140\n",
      "Epoch 144/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9406 - val_loss: 0.1103 - val_accuracy: 0.9539\n",
      "Epoch 145/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9574 - val_loss: 0.1116 - val_accuracy: 0.9539\n",
      "Epoch 146/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1316 - accuracy: 0.9539 - val_loss: 0.1128 - val_accuracy: 0.9526\n",
      "Epoch 147/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9536 - val_loss: 0.1130 - val_accuracy: 0.9551\n",
      "Epoch 148/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1203 - accuracy: 0.9572 - val_loss: 0.1151 - val_accuracy: 0.9514\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9589 - val_loss: 0.1107 - val_accuracy: 0.9589\n",
      "Epoch 150/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9577 - val_loss: 0.1109 - val_accuracy: 0.9539\n",
      "Epoch 151/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9590 - val_loss: 0.1102 - val_accuracy: 0.9551\n",
      "Epoch 152/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9583 - val_loss: 0.1198 - val_accuracy: 0.9501\n",
      "Epoch 153/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9600 - val_loss: 0.1097 - val_accuracy: 0.9601\n",
      "Epoch 154/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9596 - val_loss: 0.1201 - val_accuracy: 0.9526\n",
      "Epoch 155/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9583 - val_loss: 0.1145 - val_accuracy: 0.9564\n",
      "Epoch 156/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9583 - val_loss: 0.1295 - val_accuracy: 0.9489\n",
      "Epoch 157/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9488 - val_loss: 0.1205 - val_accuracy: 0.9551\n",
      "Epoch 158/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9509 - val_loss: 0.1166 - val_accuracy: 0.9539\n",
      "Epoch 159/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9539 - val_loss: 0.1137 - val_accuracy: 0.9551\n",
      "28/28 [==============================] - 0s 923us/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0\n",
      " 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0\n",
      " 0 1 1 0]\n",
      "[TP TN FP FN]\n",
      "423 150 296 23\n",
      "[accuracy, sensitivity, specificity, precision, F1, ROC_AUC, PR_AUC]\n",
      "[0.6423766816143498, 0.9484304932735426, 0.336322869955157, 0.588317107093185, 0.7261802575107296, 0.8254439059703594, 0.8032389335336305]\n",
      "Iteration(train):  5\n",
      "--Sampled new data--\n",
      "(3613, 3) (3613, 3)\n",
      "(401, 3) (401, 3)\n",
      "(446, 3) (446, 3)\n",
      "---Read Embeddings---\n",
      "(15685, 128)\n",
      "[[ 0.05438794  0.15712513  0.02526474 ...  0.06337012 -0.06831192\n",
      "   0.05740243]\n",
      " [ 0.0920557   0.12854572  0.07927883 ... -0.04355874 -0.02950621\n",
      "   0.01127648]\n",
      " [ 0.10265665  0.04119997  0.01358521 ... -0.07648639  0.01284278\n",
      "   0.09610651]\n",
      " ...\n",
      " [-0.06547894  0.03663263  0.12268668 ... -0.04719101 -0.08261108\n",
      "  -0.08350137]\n",
      " [-0.00914692 -0.00912238  0.11259656 ... -0.02135581 -0.1477403\n",
      "  -0.11278752]\n",
      " [ 0.02491135 -0.00382214  0.14209396 ...  0.0124865  -0.13294958\n",
      "  -0.08357669]]\n",
      "[[ 0.06255813  0.18072855  0.02906002 ...  0.07288961 -0.07857377\n",
      "   0.06602545]\n",
      " [ 0.18997227  0.26527551  0.16360507 ... -0.08989072 -0.06089097\n",
      "   0.0232709 ]\n",
      " [-0.20810853 -0.08352177 -0.02754034 ...  0.15505543 -0.02603526\n",
      "  -0.19482991]\n",
      " ...\n",
      " [ 0.07148592 -0.03999328 -0.13394184 ...  0.05152027  0.09018974\n",
      "   0.09116171]\n",
      " [ 0.01469648  0.01465706 -0.18091049 ...  0.03431268  0.23737643\n",
      "   0.1812173 ]\n",
      " [-0.10046136  0.01541376 -0.57303013 ... -0.05035501  0.53615309\n",
      "   0.33704433]]\n",
      "---TrainNN---\n",
      "0.001\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.8150 - accuracy: 0.5504 - val_loss: 0.6883 - val_accuracy: 0.7269\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.6193 - val_loss: 0.6604 - val_accuracy: 0.7232\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.6489 - val_loss: 0.6106 - val_accuracy: 0.7494\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6818 - val_loss: 0.5882 - val_accuracy: 0.7506\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.7069 - val_loss: 0.5436 - val_accuracy: 0.7793\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7462 - val_loss: 0.4832 - val_accuracy: 0.8242\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7757 - val_loss: 0.4455 - val_accuracy: 0.8566\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.8042 - val_loss: 0.4020 - val_accuracy: 0.8741\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.8231 - val_loss: 0.3585 - val_accuracy: 0.8716\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8385 - val_loss: 0.3367 - val_accuracy: 0.8903\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8615 - val_loss: 0.3054 - val_accuracy: 0.9002\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8662 - val_loss: 0.2949 - val_accuracy: 0.9052\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8716 - val_loss: 0.2903 - val_accuracy: 0.8928\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8714 - val_loss: 0.2527 - val_accuracy: 0.9227\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8909 - val_loss: 0.2445 - val_accuracy: 0.9227\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8929 - val_loss: 0.2380 - val_accuracy: 0.9252\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8927 - val_loss: 0.2392 - val_accuracy: 0.9177\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.9020 - val_loss: 0.2140 - val_accuracy: 0.9289\n",
      "Epoch 19/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.9092 - val_loss: 0.2145 - val_accuracy: 0.9327\n",
      "Epoch 20/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9037 - val_loss: 0.2111 - val_accuracy: 0.9327\n",
      "Epoch 21/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.9059 - val_loss: 0.2130 - val_accuracy: 0.9327\n",
      "Epoch 22/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.9145 - val_loss: 0.1959 - val_accuracy: 0.9401\n",
      "Epoch 23/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.9178 - val_loss: 0.2009 - val_accuracy: 0.9401\n",
      "Epoch 24/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.9154 - val_loss: 0.2130 - val_accuracy: 0.9352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.9121 - val_loss: 0.1964 - val_accuracy: 0.9352\n",
      "Epoch 26/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9225 - val_loss: 0.1953 - val_accuracy: 0.9414\n",
      "Epoch 27/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9272 - val_loss: 0.1920 - val_accuracy: 0.9414\n",
      "Epoch 28/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9232 - val_loss: 0.1926 - val_accuracy: 0.9401\n",
      "Epoch 29/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.9199 - val_loss: 0.1895 - val_accuracy: 0.9339\n",
      "Epoch 30/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9268 - val_loss: 0.1903 - val_accuracy: 0.9414\n",
      "Epoch 31/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9286 - val_loss: 0.1853 - val_accuracy: 0.9426\n",
      "Epoch 32/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9286 - val_loss: 0.1838 - val_accuracy: 0.9401\n",
      "Epoch 33/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2023 - accuracy: 0.9308 - val_loss: 0.1794 - val_accuracy: 0.9389\n",
      "Epoch 34/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9226 - val_loss: 0.1806 - val_accuracy: 0.9439\n",
      "Epoch 35/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9333 - val_loss: 0.1813 - val_accuracy: 0.9401\n",
      "Epoch 36/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9297 - val_loss: 0.1740 - val_accuracy: 0.9426\n",
      "Epoch 37/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.9340 - val_loss: 0.1816 - val_accuracy: 0.9426\n",
      "Epoch 38/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9358 - val_loss: 0.1742 - val_accuracy: 0.9414\n",
      "Epoch 39/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9303 - val_loss: 0.1743 - val_accuracy: 0.9439\n",
      "Epoch 40/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9329 - val_loss: 0.1659 - val_accuracy: 0.9451\n",
      "Epoch 41/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9347 - val_loss: 0.1659 - val_accuracy: 0.9464\n",
      "Epoch 42/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9392 - val_loss: 0.1638 - val_accuracy: 0.9451\n",
      "Epoch 43/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.9384 - val_loss: 0.1661 - val_accuracy: 0.9439\n",
      "Epoch 44/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9374 - val_loss: 0.1624 - val_accuracy: 0.9476\n",
      "Epoch 45/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9405 - val_loss: 0.1600 - val_accuracy: 0.9451\n",
      "Epoch 46/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9351 - val_loss: 0.1694 - val_accuracy: 0.9439\n",
      "Epoch 47/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9372 - val_loss: 0.1662 - val_accuracy: 0.9414\n",
      "Epoch 48/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9356 - val_loss: 0.1604 - val_accuracy: 0.9426\n",
      "Epoch 49/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9420 - val_loss: 0.1607 - val_accuracy: 0.9451\n",
      "Epoch 50/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9362 - val_loss: 0.1597 - val_accuracy: 0.9489\n",
      "Epoch 51/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9408 - val_loss: 0.1666 - val_accuracy: 0.9439\n",
      "Epoch 52/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9401 - val_loss: 0.1649 - val_accuracy: 0.9489\n",
      "Epoch 53/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9356 - val_loss: 0.1599 - val_accuracy: 0.9439\n",
      "Epoch 54/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9409 - val_loss: 0.1622 - val_accuracy: 0.9414\n",
      "Epoch 55/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9456 - val_loss: 0.1557 - val_accuracy: 0.9476\n",
      "Epoch 56/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9451 - val_loss: 0.1735 - val_accuracy: 0.9426\n",
      "Epoch 57/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9420 - val_loss: 0.1621 - val_accuracy: 0.9439\n",
      "Epoch 58/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9451 - val_loss: 0.1611 - val_accuracy: 0.9501\n",
      "Epoch 59/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9456 - val_loss: 0.1559 - val_accuracy: 0.9501\n",
      "Epoch 60/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9394 - val_loss: 0.1556 - val_accuracy: 0.9539\n",
      "Epoch 61/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9441 - val_loss: 0.1707 - val_accuracy: 0.9501\n",
      "Epoch 62/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9455 - val_loss: 0.1671 - val_accuracy: 0.9501\n",
      "Epoch 63/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9441 - val_loss: 0.1558 - val_accuracy: 0.9564\n",
      "Epoch 64/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9467 - val_loss: 0.1552 - val_accuracy: 0.9501\n",
      "Epoch 65/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9427 - val_loss: 0.1603 - val_accuracy: 0.9451\n",
      "Epoch 66/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9463 - val_loss: 0.1532 - val_accuracy: 0.9526\n",
      "Epoch 67/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9480 - val_loss: 0.1531 - val_accuracy: 0.9514\n",
      "Epoch 68/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9466 - val_loss: 0.1515 - val_accuracy: 0.9551\n",
      "Epoch 69/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9492 - val_loss: 0.1517 - val_accuracy: 0.9551\n",
      "Epoch 70/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9446 - val_loss: 0.1540 - val_accuracy: 0.9451\n",
      "Epoch 71/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9441 - val_loss: 0.1504 - val_accuracy: 0.9539\n",
      "Epoch 72/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9492 - val_loss: 0.1505 - val_accuracy: 0.9564\n",
      "Epoch 73/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9487 - val_loss: 0.1525 - val_accuracy: 0.9476\n",
      "Epoch 74/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9520 - val_loss: 0.1508 - val_accuracy: 0.9514\n",
      "Epoch 75/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9467 - val_loss: 0.1500 - val_accuracy: 0.9501\n",
      "Epoch 76/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9480 - val_loss: 0.1516 - val_accuracy: 0.9489\n",
      "Epoch 77/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9484 - val_loss: 0.1540 - val_accuracy: 0.9551\n",
      "Epoch 78/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1338 - accuracy: 0.9514 - val_loss: 0.1548 - val_accuracy: 0.9539\n",
      "Epoch 79/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9505 - val_loss: 0.1489 - val_accuracy: 0.9514\n",
      "Epoch 80/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9514 - val_loss: 0.1515 - val_accuracy: 0.9551\n",
      "Epoch 81/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9481 - val_loss: 0.1504 - val_accuracy: 0.9564\n",
      "Epoch 82/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9510 - val_loss: 0.1474 - val_accuracy: 0.9551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9506 - val_loss: 0.1467 - val_accuracy: 0.9576\n",
      "Epoch 84/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9506 - val_loss: 0.1529 - val_accuracy: 0.9551\n",
      "Epoch 85/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9506 - val_loss: 0.1548 - val_accuracy: 0.9551\n",
      "Epoch 86/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9517 - val_loss: 0.1565 - val_accuracy: 0.9564\n",
      "Epoch 87/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9523 - val_loss: 0.1477 - val_accuracy: 0.9564\n",
      "Epoch 88/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9518 - val_loss: 0.1504 - val_accuracy: 0.9539\n",
      "Epoch 89/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9481 - val_loss: 0.1443 - val_accuracy: 0.9564\n",
      "Epoch 90/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9531 - val_loss: 0.1398 - val_accuracy: 0.9526\n",
      "Epoch 91/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9539 - val_loss: 0.1448 - val_accuracy: 0.9564\n",
      "Epoch 92/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9344 - val_loss: 0.1413 - val_accuracy: 0.9551\n",
      "Epoch 93/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9413 - val_loss: 0.1519 - val_accuracy: 0.9501\n",
      "Epoch 94/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9471 - val_loss: 0.1489 - val_accuracy: 0.9564\n",
      "Epoch 95/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9503 - val_loss: 0.1400 - val_accuracy: 0.9564\n",
      "Epoch 96/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9236 - val_loss: 0.1554 - val_accuracy: 0.9526\n",
      "Epoch 97/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9451 - val_loss: 0.1454 - val_accuracy: 0.9551\n",
      "Epoch 98/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9489 - val_loss: 0.1448 - val_accuracy: 0.9539\n",
      "Epoch 99/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9509 - val_loss: 0.1527 - val_accuracy: 0.9501\n",
      "Epoch 100/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9532 - val_loss: 0.1507 - val_accuracy: 0.9526\n",
      "Epoch 101/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9492 - val_loss: 0.1430 - val_accuracy: 0.9576\n",
      "Epoch 102/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9524 - val_loss: 0.1527 - val_accuracy: 0.9564\n",
      "Epoch 103/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9500 - val_loss: 0.1466 - val_accuracy: 0.9526\n",
      "Epoch 104/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9511 - val_loss: 0.1509 - val_accuracy: 0.9551\n",
      "Epoch 105/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9516 - val_loss: 0.1630 - val_accuracy: 0.9539\n",
      "Epoch 106/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9520 - val_loss: 0.1459 - val_accuracy: 0.9576\n",
      "Epoch 107/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9516 - val_loss: 0.1409 - val_accuracy: 0.9551\n",
      "Epoch 108/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9560 - val_loss: 0.1517 - val_accuracy: 0.9551\n",
      "Epoch 109/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9542 - val_loss: 0.1443 - val_accuracy: 0.9576\n",
      "Epoch 110/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9543 - val_loss: 0.1492 - val_accuracy: 0.9551\n",
      "28/28 [==============================] - 0s 964us/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0\n",
      " 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
      " 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0\n",
      " 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0\n",
      " 0 1 1 0]\n",
      "[TP TN FP FN]\n",
      "421 157 289 25\n",
      "[accuracy, sensitivity, specificity, precision, F1, ROC_AUC, PR_AUC]\n",
      "[0.647982062780269, 0.9439461883408071, 0.35201793721973096, 0.5929577464788732, 0.7283737024221453, 0.8432403627661927, 0.8365194308206012]\n",
      "===================== n2vplus_nw8_wl32_p0.25_q0.5 =====================\n",
      "[[0.5975336322869955, 0.9596412556053812, 0.23542600896860988, 0.5565669700910273, 0.7045267489711935, 0.8313484083733838, 0.8335874001790882], [0.6311659192825112, 0.9596412556053812, 0.30269058295964124, 0.5791610284167794, 0.7223628691983123, 0.8463798789438758, 0.8405979958288516], [0.6591928251121076, 0.9417040358744395, 0.37668161434977576, 0.6017191977077364, 0.7342657342657343, 0.833975145287458, 0.8322680153785684], [0.6423766816143498, 0.9484304932735426, 0.336322869955157, 0.588317107093185, 0.7261802575107296, 0.8254439059703594, 0.8032389335336305], [0.647982062780269, 0.9439461883408071, 0.35201793721973096, 0.5929577464788732, 0.7283737024221453, 0.8432403627661927, 0.8365194308206012]]\n",
      "Mean: 0.6357 0.9507 0.3206 0.5837 0.7231 0.8361 0.8292\n",
      "Max: 0.6592 0.9596 0.3767 0.6017 0.7343 0.8464 0.8406\n",
      "Min: 0.5975 0.9417 0.2354 0.5566 0.7045 0.8254 0.8032\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "input_g_mtd = 'n2vplus_nw8_wl32_p0.25_q0.5'\n",
    "\n",
    "run_prog(input_g_mtd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper-params\n",
    "\n",
    "# SDNE\n",
    "# a_arr = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "# b_arr = [0, 10, 20, 30]\n",
    "\n",
    "# ## struc2vec\n",
    "# a_arr = [8, 16, 32, 64, 128] ## num_walks\n",
    "# b_arr = [8, 16, 32, 64, 128] ## walk_length\n",
    "\n",
    "## node2vec, node2vec+\n",
    "# a_arr = [0.25, 0.5, 1, 2, 4]\n",
    "# b_arr = [0.25, 0.5, 1, 2, 4]\n",
    "\n",
    "## deepwalk\n",
    "# a_arr = [8, 16, 32, 64, 128, 256] ## num_walks\n",
    "# b_arr = [8, 16, 32, 64, 128, 256] ## walk_length\n",
    "\n",
    "# ## ripple2vec\n",
    "# a_arr = [8, 16, 32, 64]\n",
    "# b_arr = [8, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (len(a_arr)):\n",
    "    \n",
    "#     for j in range(len(b_arr)):\n",
    "        \n",
    "#         a_str = str(a_arr[i])\n",
    "#         b_str = str(b_arr[j])\n",
    "        \n",
    "# #         input_g_mtd_str = 'a' + a_str + '_b' + b_str ## SDNE\n",
    "# #         input_g_mtd_str = 'p' + a_str + '_q' + b_str ## node2vec\n",
    "#         input_g_mtd_str = 'n2v_plus_p' + a_str + '_q' + b_str ## node2vec+\n",
    "# #         input_g_mtd_str = 'nw' + a_str + '_wl' + b_str ## deepwalk, struc2vec, ripple2vec\n",
    "        \n",
    "#         print(input_g_mtd_str)\n",
    "        \n",
    "#         run_prog(input_g_mtd_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_arr = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50] ## LINE\n",
    "# a_arr = [1, 2, 4, 8] ## GraRep\n",
    "\n",
    "# ## GAE\n",
    "# a_arr = [16, 32, 64, 128, 256, 512] ## hidden1\n",
    "# b_arr = [8, 16, 32, 64, 128, 256] ## hidden2\n",
    "\n",
    "# for i in range (len(a_arr)):\n",
    "    \n",
    "#     input_g_mtd_str = 'epochs_' + str(a_arr[i]) ## LINE\n",
    "\n",
    "# #     input_g_mtd_str = 'h' + str(a_arr[i]) + '_' + str(b_arr[i]) ## VAE\n",
    "#     print(input_g_mtd_str)\n",
    "    \n",
    "#     run_prog(input_g_mtd_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ripple2vec additional\n",
    "\n",
    "# str_arr = [8, 16, 32, 64, 128]\n",
    "\n",
    "# ## Fixed num_walks\n",
    "# for i in range (len(str_arr)):\n",
    "#     get_str = str(str_arr[i])\n",
    "        \n",
    "#     input_g_mtd_str = 'nw' + str(128) + '_wl' + str(str_arr[i])\n",
    "\n",
    "#     print(input_g_mtd_str)\n",
    "\n",
    "#     run_prog(input_g_mtd_str) \n",
    "\n",
    "# ## Fixed walk_length\n",
    "# for i in range (len(str_arr)):\n",
    "#     get_str = str(str_arr[i])\n",
    "        \n",
    "#     input_g_mtd_str = 'nw' + str(str_arr[i]) + '_wl' + str(128)\n",
    "\n",
    "#     print(input_g_mtd_str)\n",
    "\n",
    "#     run_prog(input_g_mtd_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Struc2vec additional\n",
    "\n",
    "# ## num_walks=256\n",
    "# str_arr = [8, 16, 32]\n",
    "\n",
    "# for i in range (len(str_arr)):\n",
    "#     get_str = str(str_arr[i])\n",
    "        \n",
    "#     input_g_mtd_str = 'nw' + str(256) + '_wl' + str(str_arr[i])\n",
    "\n",
    "#     print(input_g_mtd_str)\n",
    "\n",
    "#     run_prog(input_g_mtd_str) \n",
    "\n",
    "# for i in range (len(str_arr)):\n",
    "#     get_str = str(str_arr[i])\n",
    "        \n",
    "#     input_g_mtd_str = 'nw' + str(str_arr[i]) + '_wl' + str(256)\n",
    "\n",
    "#     print(input_g_mtd_str)\n",
    "\n",
    "#     run_prog(input_g_mtd_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_g_mtd_arr = ['dw_nw8_wl64', 'n2v_p0.25_q0.5', 's2v_nw256_wl8', 'line_epochs40']\n",
    "# input_g_mtd_arr = ['grarep_k2', 'sdne_a0_b10']\n",
    "# input_g_mtd_arr = ['dw-n2v-grarep-sdne', 'dw-n2v-grarep-line-sdne', 's2v-grarep-sdne', 'dw-n2v-s2v-grarep-sdne']\n",
    "\n",
    "# input_g_mtd_arr = ['GraRep_default', 'SDNE_default']\n",
    "\n",
    "\n",
    "# for i in range(len(input_g_mtd_arr)):\n",
    "    \n",
    "#     print(input_g_mtd_arr[i])\n",
    "    \n",
    "#     run_prog(input_g_mtd_arr[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_prog(input_graph_emb, get_input_neg_prop):\n",
    "    \n",
    "#     eval_metrics = []\n",
    "    \n",
    "#     for i in range(0, 5):\n",
    "        \n",
    "#         print('Iteration(train): ', (i+1))\n",
    "        \n",
    "#         acc = train(input_type = 'graph', input_mtd=input_graph_emb, input_neg_prop=get_input_neg_prop)\n",
    "#         print(acc)\n",
    "        \n",
    "#         eval_metrics.append(acc)\n",
    "        \n",
    "#     print(\"===================== \" + input_graph_emb + \" =====================\")\n",
    "#     print(eval_metrics)\n",
    "    \n",
    "#     mean = np.array(eval_metrics).mean(axis=0) # Take the mean of each column\n",
    "#     mean = np.round(mean, 4)\n",
    "#     print('Mean: ' + str(mean)[1:-1])\n",
    "          \n",
    "#     max = np.array(eval_metrics).max(axis=0)\n",
    "#     max = np.round(max, 4)\n",
    "#     print('Max: ' + str(max)[1:-1])\n",
    "          \n",
    "#     min = np.array(eval_metrics).min(axis=0)\n",
    "#     min = np.round(min, 4)\n",
    "#     print('Min: ' + str(min)[1:-1])\n",
    "#     print(\"=======================================================\")\n",
    "          \n",
    "#     with open('NN_NEW_Unbalanced_dataset_results.txt', \"a\") as f:\n",
    "#         f.write(get_input_neg_prop + '--' + input_graph_emb + ': ' + str(mean) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_g_mtd_arr = ['line_epochs40', 's2v_nw256_wl8']\n",
    "# input_neg_prog = ['1_10', '1_3', '1_1']\n",
    "\n",
    "# input_g_mtd_arr = ['s2v-grarep-line-sdne']\n",
    "# input_neg_prog = ['1_35', '1_25', '1_10', '1_3', '1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(input_neg_prog)):\n",
    "    \n",
    "#     for j in range(len(input_g_mtd_arr)):\n",
    "        \n",
    "#         print(input_g_mtd_arr[j])\n",
    "#         run_prog(input_g_mtd_arr[j], input_neg_prog[i])\n",
    "    \n",
    "#     print(\"************************************************** DONE \" + str(i+1) + \" **************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(input_g_mtd_arr)):\n",
    "    \n",
    "#     print(input_g_mtd_arr[i])\n",
    "    \n",
    "#     run_prog(input_g_mtd_arr[i])\n",
    "    \n",
    "#     print(\"************************************************** DONE \" + str(i+1) + \" **************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check dimensions\n",
    "\n",
    "# input_g_mtd_arr = ['dw-n2v', 'dw-n2v-s2v', 'dw-n2v-grarep',\n",
    "#                    's2v-grarep', 'dw-n2v-s2v-grarep',\n",
    "#                    'line-sdne', 'line-grarep', 'sdne-grarep', 'line-sdne-grarep',\n",
    "#                    'dw-n2v-line', 'dw-n2v-sdne', 'dw-n2v-line-sdne',\n",
    "#                    's2v-line', 's2v-sdne', 's2v-line-sdne',\n",
    "#                    'dw-n2v-grarep-line', 'dw-n2v-grarep-sdne', 'dw-n2v-grarep-line-sdne',\n",
    "#                    's2v-grarep-line', 's2v-grarep-sdne', 's2v-grarep-line-sdne',\n",
    "#                    'dw-n2v-s2v-grarep-line', 'dw-n2v-s2v-grarep-sdne', 'dw-n2v-s2v-grarep-line-sdne']\n",
    "\n",
    "# print(len(input_g_mtd_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit_data_path = 'Embeddings/Graph/Best/Concat/'\n",
    "\n",
    "# for i in range(len(input_g_mtd_arr)):\n",
    "    \n",
    "#     expected_dim = len(input_g_mtd_arr[i].split('-')) * 128\n",
    "    \n",
    "#     read_emb = sparse.load_npz(edit_data_path + input_g_mtd_arr[i] + '.npz')\n",
    "#     features_def = read_emb.toarray()\n",
    "\n",
    "#     print(features_def.shape)\n",
    "    \n",
    "#     if expected_dim == features_def.shape[1]:\n",
    "#         print(\"True\")\n",
    "#     else:\n",
    "#         print(input_g_mtd_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# print(np.__version__)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0IssoousoGwxV8CZRAo2p",
   "collapsed_sections": [],
   "name": "NN-Classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
