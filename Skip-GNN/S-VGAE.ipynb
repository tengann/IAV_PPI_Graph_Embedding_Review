{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["3ZYROgNpYpWy"],"authorship_tag":"ABX9TyOFeeDKe50mB2wafHc4uo2Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cESi4Q72Le8w","executionInfo":{"status":"ok","timestamp":1668667708807,"user_tz":-480,"elapsed":36381,"user":{"displayName":"ann ng","userId":"16723765352528695909"}},"outputId":"bceab0cb-e4b9-435d-9572-5c4840bcfb43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Load path"],"metadata":{"id":"zgfDgn6OdiZH"}},{"cell_type":"code","source":["## Load Path\n","root_path = 'drive/MyDrive/Skip-GNN/'\n","\n","data_path = 'drive/MyDrive/Skip-GNN/data/'\n","edges_path = data_path + 'edges/'\n","iav_root_path = data_path + 'IAV/'"],"metadata":{"id":"VOpUA7madj2v","executionInfo":{"status":"ok","timestamp":1668667708808,"user_tz":-480,"elapsed":6,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Import Libaries"],"metadata":{"id":"NcHCgVWlQH-U"}},{"cell_type":"code","source":["from __future__ import division\n","from __future__ import print_function"],"metadata":{"id":"H2dCVpRuQk27","executionInfo":{"status":"ok","timestamp":1668667708808,"user_tz":-480,"elapsed":4,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","import pandas as pd\n","import numpy as np\n","\n","import scipy.sparse as sp\n","from scipy import sparse\n","\n","# import tensorflow as tf\n","import tensorflow.compat.v1 as tf\n","\n","# import pickle as pkl\n","# import networkx as nx\n","from sklearn.preprocessing import scale, normalize\n","\n","import sys, getopt\n","\n","flags = tf.app.flags\n","FLAGS = flags.FLAGS"],"metadata":{"id":"C7pMxDflP-qk","executionInfo":{"status":"ok","timestamp":1668667712170,"user_tz":-480,"elapsed":3366,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["### initialization.py ###\n","\n","def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n","    \n","    \"\"\"\n","      Create a weight variable with Glorot & Bengio (AISTATS 2010) initialization.\n","    \"\"\"\n","    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n","    initial = tf.random_uniform([input_dim, output_dim], minval=-init_range,\n","                                maxval=init_range, dtype=tf.float64)\n","    return tf.Variable(initial, name=name)"],"metadata":{"id":"ktlm4bXcQNec","executionInfo":{"status":"ok","timestamp":1668667712170,"user_tz":-480,"elapsed":15,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# load_data"],"metadata":{"id":"T1CfWyNmjeKk"}},{"cell_type":"markdown","source":["## protein embedding"],"metadata":{"id":"Qx1HADmheS3X"}},{"cell_type":"code","source":["def load_protein_embedding(p_mtd):\n","  \n","  ## ../data/IAV/protein_embeddings/(p_mtd).npz\n","\n","  read_p_emb = sparse.load_npz(iav_root_path + 'protein_embeddings/' + p_mtd + '.npz')\n","  allx = read_p_emb.toarray()\n","  \n","  norm_features = normalize(allx) ## from sklearn.preprocessing (default l2 normalization)\n","  \n","  print(\"==================== Features ====================\")\n","  print(norm_features)\n","\n","  return norm_features"],"metadata":{"id":"lMpCrOfDbRYV","executionInfo":{"status":"ok","timestamp":1668667712171,"user_tz":-480,"elapsed":15,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# load_protein_embedding('CT')"],"metadata":{"id":"JL-ajcXfeqae","executionInfo":{"status":"ok","timestamp":1668667712171,"user_tz":-480,"elapsed":14,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def load_edgelist():\n","  edgelist = pd.read_csv(iav_root_path + 'idx_gae_edgelist.txt', sep=' ', header=None)\n","  edgelist.columns=['Protein1_ID', 'Protein2_ID','label']\n","\n","  pos_edgelist = edgelist[edgelist['label'] == 1].drop_duplicates().reset_index(drop=True)\n","  neg_edgelist = edgelist[edgelist['label'] == 0].drop_duplicates().reset_index(drop=True)\n","  \n","  # print(edgelist)\n","\n","  return pos_edgelist, neg_edgelist"],"metadata":{"id":"1FxVH2x7n2oE","executionInfo":{"status":"ok","timestamp":1668667712172,"user_tz":-480,"elapsed":15,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def load_data():\n","  \n","  '''\n","        Load protein_list\n","  '''\n","  protein_list_df = pd.read_csv(iav_root_path + 'protein_list.csv')\n","\n","  '''\n","    features: Codings for proteins\n","    Call load_protein_embedding()\n","  '''\n","  features = load_protein_embedding('CT')\n","  \n","  '''\n","    Call load_edgelist()\n","  '''\n","  posEdges, negEdges = load_edgelist()\n","  \n","  # print(posEdges)\n","  # print(negEdges)\n","\n","  for i in range(len(posEdges)):\n","    x = posEdges['Protein1_ID'][i]\n","    y = posEdges['Protein2_ID'][i]\n","\n","  '''\n","    Positive edges\n","  '''\n","  ## Generate adjacency matrix\n","  num_node = features.shape[0]\n","  adj = np.zeros((num_node,num_node))\n","\n","  for i in range(len(posEdges)):\n","    x = posEdges['Protein1_ID'][i]\n","    y = posEdges['Protein2_ID'][i]\n","\n","    adj[x][y] = 1\n","    adj[y][x] = 1\n","\n","  adj = sp.csr_matrix(adj) ## Compressed Sparse Row Format\n","\n","  print(\"==================== Adjacency Matrix ====================\")\n","  print(adj)\n","\n","  '''\n","    Negative edges\n","  '''\n","  ## Generate highly negative sets\n","  rows = []\n","  cols = []\n","  \n","  for i in range(len(negEdges)):\n","    rows.append(int(negEdges['Protein1_ID'][i]))\n","    cols.append(int(negEdges['Protein2_ID'][i]))\n","  \n","  X = np.array(rows)\n","  Y = np.array(cols)\n","  falseEdges = np.vstack((X,Y)).transpose()\n","\n","  print(\"==================== False Edges ====================\")\n","  print(falseEdges)\n","  \n","  return adj, features, falseEdges"],"metadata":{"id":"IfRsew44jgyg","executionInfo":{"status":"ok","timestamp":1668667712693,"user_tz":-480,"elapsed":536,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# adj, features, falseEdges = load_data()"],"metadata":{"id":"cYhuB7btrUuH","executionInfo":{"status":"ok","timestamp":1668667712694,"user_tz":-480,"elapsed":8,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# preprocessing.py"],"metadata":{"id":"3ZYROgNpYpWy"}},{"cell_type":"code","source":["# preprocess_graph, construct_feed_dict, sparse_to_tuple, construct_optimizer_list\n","\n","def sparse_to_tuple(sparse_mx):\n","    if not sp.isspmatrix_coo(sparse_mx):\n","        sparse_mx = sparse_mx.tocoo()\n","    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n","    values = sparse_mx.data\n","    shape = sparse_mx.shape\n","    return coords, values, shape\n","\n","def preprocess_graph(adj):\n","    adj = sp.coo_matrix(adj)\n","    adj_ = adj + sp.eye(adj.shape[0])\n","    rowsum = np.array(adj_.sum(1))\n","    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n","    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n","    return sparse_to_tuple(adj_normalized)\n","\n","def construct_feed_dict(adj_normalized, adj, features, placeholders):\n","    # construct feed dictionary\n","    feed_dict = dict()\n","    feed_dict.update({placeholders['features']: features})\n","    feed_dict.update({placeholders['adj']: adj_normalized})\n","    feed_dict.update({placeholders['adj_orig']: adj})\n","    return feed_dict\n","\n","def construct_optimizer_list(num_node, posEdges, falseEdges):\n","    \n","    mask_index = []\n","    \n","    for x in posEdges:\n","        temp = x[0] * num_node + x[1]\n","        mask_index.append(temp)\n","\n","    for x in falseEdges:\n","        temp = x[0] * num_node + x[1]\n","        mask_index.append(temp)\n","\n","    return np.array(mask_index)"],"metadata":{"id":"JACv9uFfY3-L","executionInfo":{"status":"ok","timestamp":1668667712694,"user_tz":-480,"elapsed":8,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## make_test_edges"],"metadata":{"id":"d3QjFW7ZyYz9"}},{"cell_type":"code","source":["def make_test_edges(weightRate, adj, falseEdges):\n","    '''\n","      Function to build test set with 10% positive links and 10% highly negative links\n","      NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n","    '''\n","\n","    # Remove diagonal elements\n","    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n","    adj.eliminate_zeros()\n","\n","    # Check that diag is zero:\n","    assert np.diag(adj.todense()).sum() == 0\n","\n","    adj_triu = sp.triu(adj)\n","    adj_tuple = sparse_to_tuple(adj_triu)\n","    \n","    edges = adj_tuple[0]\n","    edges_all = sparse_to_tuple(adj)[0]\n","\n","    posNum = edges.shape[0]\n","    num_test = int(np.floor(posNum / 10.))\n","    num_train = edges.shape[0] - num_test\n","\n","    # Generate positive sets\n","    all_edge_idx = list(range(posNum))\n","    np.random.shuffle(all_edge_idx)\n","    train_edge_idx = all_edge_idx[:num_train]\n","    train_edges = edges[train_edge_idx]\n","    test_edge_idx = all_edge_idx[num_train:(num_train + num_test)]\n","    test_edges = edges[test_edge_idx]\n","    \n","    falseNum = falseEdges.shape[0]\n","    num_neg_test = int(np.floor(falseNum/10.))\n","    num_neg_train = falseNum - num_neg_test\n","\n","    # Generate negative sets\n","    all_edge_neg_idx = list(range(falseNum))\n","    np.random.shuffle(all_edge_neg_idx)\n","    train_edge_neg_idx = all_edge_neg_idx[:num_neg_train]\n","    test_edge_neg_idx = all_edge_neg_idx[num_neg_train:(num_neg_train+num_neg_test)]\n","    train_edges_false = falseEdges[train_edge_neg_idx]\n","    test_edges_false = falseEdges[test_edge_neg_idx]\n","\n","    # Re-build training adjacency matrix\n","    adj_train = np.zeros(adj.shape)\n","    facNeg = -0.001\n","    facPos = weightRate * facNeg\n","\n","    for x in train_edges:\n","        adj_train[x[0]][x[1]] = facPos\n","        adj_train[x[1]][x[0]] = facPos\n","    \n","    for x in train_edges_false:\n","        adj_train[x[0]][x[1]] = facNeg\n","        adj_train[x[1]][x[0]] = facNeg\n","\n","    adj_train = sp.csr_matrix(adj_train)\n","\n","\n","    return adj_train, train_edges, train_edges_false, test_edges, test_edges_false"],"metadata":{"id":"XIgNzpM33MR7","executionInfo":{"status":"ok","timestamp":1668667712695,"user_tz":-480,"elapsed":8,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# layers.py"],"metadata":{"id":"A9SO8SglV6yV"}},{"cell_type":"code","source":["# from initialization import *\n","\n","# Global unique layer ID dictionary for layer name assignment\n","_LAYER_UIDS = {}\n","\n","def get_layer_uid(layer_name=''):\n","    \"\"\"\n","      Helper function, assigns unique layer IDs\n","    \"\"\"\n","    if layer_name not in _LAYER_UIDS:\n","        _LAYER_UIDS[layer_name] = 1\n","        return 1\n","    else:\n","        _LAYER_UIDS[layer_name] += 1\n","        return _LAYER_UIDS[layer_name]\n","\n","\n","def dropout_sparse(x, keep_prob, num_nonzero_elems):\n","    \"\"\"\n","      Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements)\n","    \"\"\"\n","    noise_shape = [num_nonzero_elems]\n","    random_tensor = keep_prob\n","    random_tensor += tf.random_uniform(noise_shape)\n","    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n","    pre_out = tf.sparse_retain(x, dropout_mask)\n","    #return pre_out * (1./keep_prob)\n","    return x\n","\n","\n","class Layer(object):\n","    \n","    \"\"\"\n","      Base layer class. Defines basic API for all layer objects.\n","\n","      # Properties\n","          name: String, defines the variable scope of the layer.\n","\n","      # Methods\n","          _call(inputs): Defines computation graph of layer\n","              (i.e. takes input, returns output)\n","          __call__(inputs): Wrapper for _call()\n","    \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        allowed_kwargs = {'name', 'logging'}\n","        for kwarg in kwargs.keys():\n","            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n","        name = kwargs.get('name')\n","        if not name:\n","            layer = self.__class__.__name__.lower()\n","            name = layer + '_' + str(get_layer_uid(layer))\n","        self.name = name\n","        self.vars = {}\n","        logging = kwargs.get('logging', False)\n","        self.logging = logging\n","        self.issparse = False\n","\n","    def _call(self, inputs):\n","        return inputs\n","\n","    def __call__(self, inputs):\n","        with tf.name_scope(self.name):\n","            outputs = self._call(inputs)\n","            return outputs\n","\n","\n","class GraphConvolution(Layer):\n","    \"\"\"\n","      Basic graph convolution layer for undirected graph without edge labels.\n","    \"\"\"\n","    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu, **kwargs):\n","        super(GraphConvolution, self).__init__(**kwargs)\n","        with tf.variable_scope(self.name + '_vars'):\n","            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n","        self.dropout = dropout\n","        self.adj = adj\n","        self.act = act\n","\n","    def _call(self, inputs):\n","        x = inputs\n","        #x = tf.nn.dropout(x, 1-self.dropout)\n","        x = tf.matmul(x, self.vars['weights'])\n","        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n","        outputs = self.act(x)\n","        return outputs\n","\n","\n","class GraphConvolutionSparse(Layer):\n","    \"\"\"\n","      Graph convolution layer for sparse inputs.\n","    \"\"\"\n","    def __init__(self, input_dim, output_dim, adj, features_nonzero, dropout=0., act=tf.nn.relu, **kwargs):\n","        super(GraphConvolutionSparse, self).__init__(**kwargs)\n","        with tf.variable_scope(self.name + '_vars'):\n","            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name=\"weights\")\n","        self.dropout = dropout\n","        self.adj = adj\n","        self.act = act\n","        self.issparse = True\n","        self.features_nonzero = features_nonzero\n","\n","    def _call(self, inputs):\n","        x = inputs\n","        x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n","        x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n","        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n","        outputs = self.act(x)\n","        return outputs\n","\n","\n","class InnerProductDecoder(Layer):\n","    \"\"\"\n","      Decoder model layer for link prediction.\n","    \"\"\"\n","    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n","        super(InnerProductDecoder, self).__init__(**kwargs)\n","        self.dropout = dropout\n","        self.act = act\n","\n","    def _call(self, inputs):\n","        inputs = tf.nn.dropout(inputs, 1-self.dropout)\n","        x = tf.transpose(inputs)\n","        x = tf.matmul(inputs, x)\n","        x = tf.reshape(x, [-1])\n","        outputs = self.act(x)\n","        return "],"metadata":{"id":"DMfE71iaV899","executionInfo":{"status":"ok","timestamp":1668667712695,"user_tz":-480,"elapsed":8,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# model.py"],"metadata":{"id":"qg5geGubWUL4"}},{"cell_type":"code","source":["# from layers import GraphConvolution, GraphConvolutionSparse, InnerProductDecoder\n","\n","class Model(object):\n","    def __init__(self, **kwargs):\n","        allowed_kwargs = {'name', 'logging'}\n","        for kwarg in kwargs.keys():\n","            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n","\n","        for kwarg in kwargs.keys():\n","            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n","        name = kwargs.get('name')\n","        if not name:\n","            name = self.__class__.__name__.lower()\n","        self.name = name\n","\n","        logging = kwargs.get('logging', False)\n","        self.logging = logging\n","\n","        self.vars = {}\n","\n","    def _build(self):\n","        raise NotImplementedError\n","\n","    def build(self):\n","        \"\"\" Wrapper for _build() \"\"\"\n","        with tf.variable_scope(self.name):\n","            self._build()\n","        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n","        self.vars = {var.name: var for var in variables}\n","\n","    def fit(self):\n","        pass\n","\n","    def predict(self):\n","        pass\n","\n","\n","class GCNModelAE(Model):\n","    def __init__(self, placeholders, num_features, features_nonzero, **kwargs):\n","        super(GCNModelAE, self).__init__(**kwargs)\n","\n","        self.inputs = placeholders['features']\n","        self.input_dim = num_features\n","        self.features_nonzero = features_nonzero\n","        self.adj = placeholders['adj']\n","        self.dropout = placeholders['dropout']\n","        self.build()\n","\n","    def _build(self):\n","        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n","                                              output_dim=FLAGS.hidden1,\n","                                              adj=self.adj,\n","                                              features_nonzero=self.features_nonzero,\n","                                              act=tf.nn.relu,\n","                                              dropout=self.dropout,\n","                                              logging=self.logging)(self.inputs)\n","\n","        self.embeddings = GraphConvolution(input_dim=FLAGS.hidden1,\n","                                           output_dim=FLAGS.hidden2,\n","                                           adj=self.adj,\n","                                           act=lambda x: x,\n","                                           dropout=self.dropout,\n","                                           logging=self.logging)(self.hidden1)\n","\n","        self.z_mean = self.embeddings\n","\n","        self.reconstructions = InnerProductDecoder(input_dim=FLAGS.hidden2,\n","                                        act=lambda x: x,\n","                                      logging=self.logging)(self.embeddings)\n","\n","\n","class GCNModelVAE(Model):\n","    def __init__(self, placeholders, num_features, num_nodes, features_nonzero, **kwargs):\n","        super(GCNModelVAE, self).__init__(**kwargs)\n","\n","        self.inputs = placeholders['features']\n","        self.input_dim = num_features\n","        self.features_nonzero = features_nonzero\n","        self.n_samples = num_nodes\n","        self.adj = placeholders['adj']\n","        self.dropout = placeholders['dropout']\n","        self.build()\n","\n","    def _build(self):\n","        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n","                                              output_dim=FLAGS.hidden1,\n","                                              adj=self.adj,\n","                                              features_nonzero=self.features_nonzero,\n","                                              act=tf.nn.relu,\n","                                              dropout=self.dropout,\n","                                              logging=self.logging)(self.inputs)\n","\n","        self.z_mean = GraphConvolution(input_dim=FLAGS.hidden1,\n","                                       output_dim=FLAGS.hidden2,\n","                                       adj=self.adj,\n","                                       act=lambda x: x,\n","                                       dropout=self.dropout,\n","                                       logging=self.logging)(self.hidden1)\n","\n","        self.z_log_std = GraphConvolution(input_dim=FLAGS.hidden1,\n","                                          output_dim=FLAGS.hidden2,\n","                                          adj=self.adj,\n","                                          act=lambda x: x,\n","                                          dropout=self.dropout,\n","                                          logging=self.logging)(self.hidden1)\n","\n","        self.z = self.z_mean + tf.random_normal([self.n_samples, FLAGS.hidden2], dtype=tf.float64) * tf.exp(self.z_log_std)\n","\n","        self.reconstructions = InnerProductDecoder(input_dim=FLAGS.hidden2,\n","                                        act=lambda x: x,\n","                                      logging=self.logging)(self.z)"],"metadata":{"id":"pMe2IhkTXqqp","executionInfo":{"status":"ok","timestamp":1668667712696,"user_tz":-480,"elapsed":9,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# optimizer.py"],"metadata":{"id":"rl3_0ruAWZtO"}},{"cell_type":"code","source":["class OptimizerAE(object):\n","    def __init__(self, preds, labels, pos_weight, norm, learning_rate):\n","        preds_sub = preds\n","        labels_sub = labels\n","\n","        self.cost = norm * tf.reduce_mean(\n","            tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n","        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # Adam Optimizer\n","\n","        self.opt_op = self.optimizer.minimize(self.cost)\n","        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n","\n","        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n","                                           tf.cast(labels_sub, tf.int32))\n","        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n","\n","class OptimizerVAE(object):\n","    def __init__(self, preds, labels, model, num_nodes, pos_weight, norm, learning_rate):\n","        preds_sub = preds\n","        labels_sub = labels\n","\n","        self.cost = norm * tf.reduce_mean(\n","            tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n","        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)  # Adam Optimizer\n","\n","        # Latent loss\n","        self.log_lik = self.cost\n","        self.kl = (0.5 / num_nodes) * tf.reduce_mean(tf.reduce_sum(1 + 2 * model.z_log_std - tf.square(model.z_mean) -\n","                                                                   tf.square(tf.exp(model.z_log_std)), 1))\n","        self.cost -= self.kl\n","\n","        self.opt_op = self.optimizer.minimize(self.cost)\n","        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n","\n","        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n","                                           tf.cast(labels_sub, tf.int32))\n","        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))"],"metadata":{"id":"hgAvw5rEX8Yi","executionInfo":{"status":"ok","timestamp":1668667712696,"user_tz":-480,"elapsed":8,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["#trainGcn"],"metadata":{"id":"hJ4FKF2jQVbl"}},{"cell_type":"code","source":["# from optimizer import OptimizerAE, OptimizerVAE\n","# from model import GCNModelAE, GCNModelVAE\n","# from preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, construct_optimizer_list\n","\n","## from load_data(): features\n","## from make_test_edges() adj_train, train_edges, train_edges_false, test_edges, test_edges_false\n","\n","def train_gcn(features, adj_train, train_edges, train_edges_false, test_edges, test_edges_false):\n","    \n","    ## Settings [__init__ (self, args)]\n","\n","    flags = tf.app.flags\n","    FLAGS = flags.FLAGS\n","\n","    flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n","    flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n","    flags.DEFINE_integer('hidden1', 32, 'Number of units in hidden layer 1.') ## To be optimized\n","    flags.DEFINE_integer('hidden2', 16, 'Number of units in hidden layer 2.')\n","    flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n","    flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n","    \n","    flags.DEFINE_string('model', 'gcn_vae', 'Model string.')\n","    flags.DEFINE_integer('features', 1, 'Whether to use features (1) or not (0).')\n","\n","    model_str = FLAGS.model\n","\n","    # 1-dim index array, used in cost function to only focus on those interactions with high confidence\n","    mask_index = construct_optimizer_list(features.shape[0], train_edges, train_edges_false)\n","\n","    # Store original adjacency matrix (without diagonal entries) for later\n","    adj_orig = adj_train\n","    adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n","    adj_orig.eliminate_zeros()\n","\n","    adj = adj_train\n","\n","    if FLAGS.features == 0:\n","        features = sp.identity(features.shape[0])  # featureless\n","\n","    # Some preprocessing\n","    adj_norm = preprocess_graph(adj)\n","\n","    # Define placeholders\n","    placeholders = {\n","        'features': tf.sparse_placeholder(tf.float64),\n","        'adj': tf.sparse_placeholder(tf.float64),\n","        'adj_orig': tf.sparse_placeholder(tf.float64),\n","        'dropout': tf.placeholder_with_default(0., shape=())\n","    }\n","\n","    num_nodes = adj.shape[0]\n","\n","    features = sparse_to_tuple(features.tocoo()) ## Coordinate Format (COO) - fast format for constructing sparse matrices\n","    num_features = features[2][1]\n","    features_nonzero = features[1].shape[0]\n","\n","    # Create model\n","    model = None\n","    if model_str == 'gcn_ae':\n","        model = GCNModelAE(placeholders, num_features, features_nonzero)\n","    elif model_str == 'gcn_vae':\n","        model = GCNModelVAE(placeholders, num_features, num_nodes, features_nonzero)\n","\n","    pos_weight = 1\n","    norm = 1\n","\n","    ## VAE\n","    # pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n","    # norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n","\n","\n","    # Optimizer\n","    with tf.name_scope('optimizer'):\n","        if model_str == 'gcn_ae':\n","            opt = OptimizerAE(preds=model.reconstructions,\n","                          labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n","                                                                      validate_indices=False), [-1]),\n","                          pos_weight=pos_weight,\n","                          norm=norm,\n","                          mask=mask_index)\n","        elif model_str == 'gcn_vae':\n","            opt = OptimizerVAE(preds=model.reconstructions,\n","                           labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n","                                                                       validate_indices=False), [-1]),\n","                           model=model, num_nodes=num_nodes,\n","                           pos_weight=pos_weight,\n","                           norm=norm,\n","                           mask=mask_index)\n","\n","    # Initialize session\n","    sess = tf.Session()\n","    sess.run(tf.global_variables_initializer())\n","\n","    adj_label = adj_train + sp.eye(adj_train.shape[0])\n","    adj_label = sparse_to_tuple(adj_label)\n","\n","    # Train model\n","    for epoch in range(FLAGS.epochs):\n","\n","        t = time.time()\n","        \n","        # Construct feed dictionary\n","        feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n","        feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n","        \n","        # Run single weight update\n","        outs = sess.run([opt.opt_op, opt.cost], feed_dict=feed_dict)\n","        \n","        # Compute average loss\n","        avg_cost = outs[1]\n","        avg_accuracy = outs[2]\n","\n","        print(\"Epoch:\", '%04d' % (epoch + 1),\n","              \"train_loss=\", \"{:.5f}\".format(avg_cost),\n","              \"train_acc=\", \"{:.5f}\".format(avg_accuracy),\n","              \"time=\", \"{:.5f}\".format(time.time() - t))\n","\n","        # print(\"Epoch:\", '%04d' % (epoch+1), \"train_loss=\", \"{:.5f}\".format(outs[1]))\n","\n","\n","    print(\"Optimization Finished!\")\n","    \n","    ## Return embedding for each protein\n","    emb = sess.run(model.z_mean,feed_dict=feed_dict) ## save_embeddings(self, output, node_list)\n","    \n","    print(\"==================== Embedding ====================\")\n","    print(emb)\n","    print(emb.shape)\n","\n","    return emb"],"metadata":{"id":"IKNQ_XniLrv5","executionInfo":{"status":"ok","timestamp":1668667712696,"user_tz":-480,"elapsed":8,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Run program here"],"metadata":{"id":"GwroL5WtQdJs"}},{"cell_type":"code","source":["# from preprocessing import make_test_edges\n","# from input_data import load_data\n","# from trainGcn import train_gcn\n","# from trainNN import generate_data, train_nn\n","\n","def run_program(weightRate): ## default weightRate = 1\n","    \n","    adj, features, falseEdges = load_data()\n","\n","    # Generate training and test data \n","    adj_train, train_edges, train_edges_false, test_edges, test_edges_false = make_test_edges(weightRate, adj, falseEdges)\n","\n","    print(adj_train.shape)\n","    print(train_edges.shape, train_edges_false.shape)\n","    print(test_edges.shape, test_edges_false.shape)\n","\n","    # Embeddings returned by S-VGAE\n","    emb = train_gcn(features,adj_train,train_edges,train_edges_false,test_edges,test_edges_false)\n","\n","    print(emb)\n","\n","    # # Read FNN train, test, val datasets\n","    # X_train,Y_train = generate_data(emb, train_edges, train_edges_false)\n","    # X_test,Y_test = generate_data(emb, test_edges, test_edges_false)\n","\n","    # # Final softmax classifier\n","    # acc = train_nn(X_train,Y_train,X_test,Y_test)\n","    # print 'accuracy:',acc[0]\n","    # print 'sensitivity:',acc[1]\n","    # print 'specificity:',acc[2]\n","    # print 'precision:',acc[3]"],"metadata":{"id":"FK6IZqIa5hrc","executionInfo":{"status":"ok","timestamp":1668667712697,"user_tz":-480,"elapsed":8,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["### Call train()\n","run_program(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"a1OjcxLuSEo1","executionInfo":{"status":"error","timestamp":1668667725386,"user_tz":-480,"elapsed":12697,"user":{"displayName":"ann ng","userId":"16723765352528695909"}},"outputId":"2533b9a8-4c89-43fd-bea6-536026f4fe85"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["==================== Features ====================\n","[[0.11339099 0.09719228 0.14578842 ... 0.         0.         0.        ]\n"," [0.04855793 0.08092989 0.09711586 ... 0.         0.         0.        ]\n"," [0.         0.05268837 0.05268837 ... 0.         0.         0.        ]\n"," ...\n"," [0.15762208 0.23643312 0.07881104 ... 0.         0.         0.        ]\n"," [0.         0.17052613 0.05684204 ... 0.         0.         0.        ]\n"," [0.         0.11639519 0.08729639 ... 0.         0.         0.        ]]\n","==================== Adjacency Matrix ====================\n","  (0, 41)\t1.0\n","  (0, 43)\t1.0\n","  (0, 46)\t1.0\n","  (0, 51)\t1.0\n","  (0, 53)\t1.0\n","  (0, 54)\t1.0\n","  (0, 60)\t1.0\n","  (0, 67)\t1.0\n","  (0, 74)\t1.0\n","  (0, 76)\t1.0\n","  (0, 84)\t1.0\n","  (0, 90)\t1.0\n","  (0, 93)\t1.0\n","  (0, 97)\t1.0\n","  (0, 99)\t1.0\n","  (0, 105)\t1.0\n","  (0, 112)\t1.0\n","  (0, 116)\t1.0\n","  (0, 119)\t1.0\n","  (0, 124)\t1.0\n","  (0, 126)\t1.0\n","  (0, 133)\t1.0\n","  (0, 136)\t1.0\n","  (0, 137)\t1.0\n","  (0, 142)\t1.0\n","  :\t:\n","  (15677, 1)\t1.0\n","  (15677, 2)\t1.0\n","  (15677, 7)\t1.0\n","  (15677, 9)\t1.0\n","  (15678, 0)\t1.0\n","  (15678, 1)\t1.0\n","  (15678, 2)\t1.0\n","  (15678, 4)\t1.0\n","  (15678, 7)\t1.0\n","  (15678, 9)\t1.0\n","  (15678, 31)\t1.0\n","  (15678, 33)\t1.0\n","  (15679, 7)\t1.0\n","  (15680, 7)\t1.0\n","  (15682, 1)\t1.0\n","  (15682, 7)\t1.0\n","  (15683, 0)\t1.0\n","  (15683, 1)\t1.0\n","  (15683, 2)\t1.0\n","  (15683, 7)\t1.0\n","  (15683, 9)\t1.0\n","  (15684, 0)\t1.0\n","  (15684, 1)\t1.0\n","  (15684, 7)\t1.0\n","  (15684, 9)\t1.0\n","==================== False Edges ====================\n","[[   42     0]\n"," [   44     0]\n"," [   45     0]\n"," ...\n"," [15178    29]\n"," [15332    29]\n"," [15656    29]]\n","(15685, 15685)\n","(43206, 2) (201677, 2)\n","(4800, 2) (22408, 2)\n"]},{"output_type":"error","ename":"UnrecognizedFlagError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-3aa71507138a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Call train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-315fba4bfe04>\u001b[0m in \u001b[0;36mrun_program\u001b[0;34m(weightRate)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Embeddings returned by S-VGAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_edges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_edges_false\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_edges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_edges_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-f32222bdf492>\u001b[0m in \u001b[0;36mtrain_gcn\u001b[0;34m(features, adj_train, train_edges, train_edges_false, test_edges, test_edges_false)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whether to use features (1) or not (0).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# 1-dim index array, used in cost function to only focus on those interactions with high confidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# a flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m       \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[0;32m--> 651\u001b[0;31m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"]}]},{"cell_type":"code","source":["# def main():\n","    \n","#     opts, args = getopt.getopt(sys.argv[1:],\"d:w:\",[\"dataset=\", \"wr=\"])\n","    \n","#     dataset = \"IAV\" ## Placeholder\n","#     weightRate = 1\n","\n","#     for opt, arg in opts:\n","#         if opt == '--dataset':\n","#             dataset = arg\n","#         if opt == '--wr':\n","#             weightRate=int(arg)\n","\n","#     # print(dataset)\n","#     # print(weightRate)\n","\n","#     ### Call train()\n","#     train(weightRate)"],"metadata":{"id":"LrRMapSE8y1A","executionInfo":{"status":"aborted","timestamp":1668667725387,"user_tz":-480,"elapsed":9,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train(1) "],"metadata":{"id":"w5lfRzmz6drT","executionInfo":{"status":"aborted","timestamp":1668667725388,"user_tz":-480,"elapsed":10,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## SAVE EMBEDDING\n","# np.save('../data/IAV/SVGAE_embeddings/' + emb_name + '.npy', emb) ## save path"],"metadata":{"id":"ysMS4IVI56Hl","executionInfo":{"status":"aborted","timestamp":1668667725389,"user_tz":-480,"elapsed":11,"user":{"displayName":"ann ng","userId":"16723765352528695909"}}},"execution_count":null,"outputs":[]}]}